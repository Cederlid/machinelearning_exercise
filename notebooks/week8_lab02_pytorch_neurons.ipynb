{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc50656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d7279",
   "metadata": {},
   "source": [
    "# Load and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720a1c3",
   "metadata": {},
   "source": [
    "**1) ladda**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47db2b",
   "metadata": {},
   "source": [
    "Vi kommer att använda följande dataset:\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/320/student+performance\n",
    "\n",
    "Vårt mål kommer vara att förutspå varje elevs slutbetyg, beroende på olika faktorer.\n",
    "I hemsidan kan du läsa på mer detaljerat om vad varje kolumn beskriver!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fbb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = pd.read_csv('../data/student-por.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984bdd0",
   "metadata": {},
   "source": [
    "**2) Initial data check**\n",
    "\n",
    "Vi vill predikta 'G3' (slutbetyg) givet övriga attribut.\n",
    "\n",
    "Slutbetyget anges med ett värde på 0-20, där 20 är bästa betyg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e49328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0    ...      4        3      4     1     1      3        4   0  11  11  \n",
       "1    ...      5        3      3     1     1      3        2   9  11  11  \n",
       "2    ...      4        3      2     2     3      3        6  12  13  12  \n",
       "3    ...      3        2      2     1     1      5        0  14  14  14  \n",
       "4    ...      4        3      2     1     2      5        0  11  13  13  \n",
       "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
       "644  ...      5        4      2     1     2      5        4  10  11  10  \n",
       "645  ...      4        3      4     1     1      1        4  15  15  16  \n",
       "646  ...      1        1      1     1     1      5        6  11  12   9  \n",
       "647  ...      2        4      5     3     4      2        6  10  10  10  \n",
       "648  ...      4        4      1     3     4      5        4  10  11  11  \n",
       "\n",
       "[649 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347dbff",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9828f74c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G3\n",
      "11    104\n",
      "10     97\n",
      "13     82\n",
      "12     72\n",
      "14     63\n",
      "15     49\n",
      "16     36\n",
      "9      35\n",
      "8      35\n",
      "17     29\n",
      "18     15\n",
      "0      15\n",
      "7      10\n",
      "6       3\n",
      "19      2\n",
      "1       1\n",
      "5       1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(students_df.G3.value_counts())\n",
    "\n",
    "students_df.G3.hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22252592",
   "metadata": {},
   "source": [
    "Som syns ovan ser vi att ingen fått maxbetyg (20) men att två elever uppnåde 19 iaf. De allra flesta verkar fått slutbetyg mellan 9 till 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd369334",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5fa6c",
   "metadata": {},
   "source": [
    "**3) välj bort vissa kolumner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101b736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>reason</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>higher</th>\n",
       "      <th>internet</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>course</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>course</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>home</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>home</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>course</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>course</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>course</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>course</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>course</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age famsize Pstatus  Medu  Fedu  reason  studytime  failures  \\\n",
       "0       GP   F   18     GT3       A     4     4  course          2         0   \n",
       "1       GP   F   17     GT3       T     1     1  course          2         0   \n",
       "2       GP   F   15     LE3       T     1     1   other          2         0   \n",
       "3       GP   F   15     GT3       T     4     2    home          3         0   \n",
       "4       GP   F   16     GT3       T     3     3    home          2         0   \n",
       "..     ...  ..  ...     ...     ...   ...   ...     ...        ...       ...   \n",
       "644     MS   F   19     GT3       T     2     3  course          3         1   \n",
       "645     MS   F   18     LE3       T     3     1  course          2         0   \n",
       "646     MS   F   18     GT3       T     1     1  course          2         0   \n",
       "647     MS   M   17     LE3       T     3     1  course          1         0   \n",
       "648     MS   M   18     LE3       T     3     2  course          1         0   \n",
       "\n",
       "    higher internet  Dalc  Walc  health  G1  G2  G3  \n",
       "0      yes       no     1     1       3   0  11  11  \n",
       "1      yes      yes     1     1       3   9  11  11  \n",
       "2      yes      yes     2     3       3  12  13  12  \n",
       "3      yes      yes     1     1       5  14  14  14  \n",
       "4      yes       no     1     2       5  11  13  13  \n",
       "..     ...      ...   ...   ...     ...  ..  ..  ..  \n",
       "644    yes      yes     1     2       5  10  11  10  \n",
       "645    yes      yes     1     1       1  15  15  16  \n",
       "646    yes       no     1     1       5  11  12   9  \n",
       "647    yes      yes     3     4       2  10  10  10  \n",
       "648    yes      yes     3     4       5  10  11  11  \n",
       "\n",
       "[649 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vi väljer bort ett par kolumner för enkelhetens skull, och tar endast med ett par utvalda\n",
    "\n",
    "target_column = ['G3']\n",
    "feature_columns = ['school', 'sex', 'age', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'reason',\n",
    "                   'studytime', 'failures', 'higher', 'internet', 'Dalc', 'Walc', 'health', 'G1', 'G2']\n",
    "\n",
    "students_df = students_df[feature_columns + target_column]\n",
    "\n",
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df5e1f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a130c",
   "metadata": {},
   "source": [
    "**4) transformera data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ecf1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 649 entries, 0 to 648\n",
      "Data columns (total 18 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   school     649 non-null    object\n",
      " 1   sex        649 non-null    object\n",
      " 2   age        649 non-null    int64 \n",
      " 3   famsize    649 non-null    object\n",
      " 4   Pstatus    649 non-null    object\n",
      " 5   Medu       649 non-null    int64 \n",
      " 6   Fedu       649 non-null    int64 \n",
      " 7   reason     649 non-null    object\n",
      " 8   studytime  649 non-null    int64 \n",
      " 9   failures   649 non-null    int64 \n",
      " 10  higher     649 non-null    object\n",
      " 11  internet   649 non-null    object\n",
      " 12  Dalc       649 non-null    int64 \n",
      " 13  Walc       649 non-null    int64 \n",
      " 14  health     649 non-null    int64 \n",
      " 15  G1         649 non-null    int64 \n",
      " 16  G2         649 non-null    int64 \n",
      " 17  G3         649 non-null    int64 \n",
      "dtypes: int64(11), object(7)\n",
      "memory usage: 91.4+ KB\n"
     ]
    }
   ],
   "source": [
    "students_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7ceb2",
   "metadata": {},
   "source": [
    "Alla inputs och outputs för neurala nätverk måste först siffror (integer eller floats). Vi ser att flera av våra kolumner (bl.a. *school* och *sex*) inte är det, och behöver således åtgärda det. Ett av kolumnerna är dessutom kategorisk, men vi återkommer till den strax.\n",
    "\n",
    "Först och främst ser vi att ett antal kolumner (*school*, *sex*, *famsize*, *pstatus*, *higher* och *internet*) är binära - dvs att de bara antar två värden. Dessa kan vi helt enkelt omvandla dessa två värden till 1 och 0, respektive. \n",
    "\n",
    "**Kontrollera själv att kolumnerna ovan verkligen är binära**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f373c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['school', 'sex', 'famsize', 'Pstatus', 'higher', 'internet']\n",
    "\n",
    "for column in binary_columns:\n",
    "    \n",
    "    first_value = students_df[column].unique()[0] # extrahera ett av de binära värdena\n",
    "    transformed_column = [1 if value == first_value else 0 for value in students_df[column]]\n",
    "    \n",
    "    students_df[column] = transformed_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e9dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school\n",
      "1    423\n",
      "0    226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sex\n",
      "1    383\n",
      "0    266\n",
      "Name: count, dtype: int64\n",
      "\n",
      "famsize\n",
      "1    457\n",
      "0    192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pstatus\n",
      "0    569\n",
      "1     80\n",
      "Name: count, dtype: int64\n",
      "\n",
      "higher\n",
      "1    580\n",
      "0     69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "internet\n",
      "0    498\n",
      "1    151\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Kontrollera nu att alla värden omvandlats till 1 och 0 i de binära kolumnerna\n",
    "\n",
    "for column in binary_columns:\n",
    "    print(students_df[column].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1da041",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b0d15",
   "metadata": {},
   "source": [
    "Nu återstår att åtgärda den kategoriska kolumnen *reason*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10599de1",
   "metadata": {},
   "source": [
    "Vi behöver göra om den här kolumnen till siffror, och en strategi för att hantera kategoriska kolumner är att omvandla dem \n",
    "till kolumner, en varje varje värde - och på enklaste sätt ange 1 eller 0 för respektive kolumn på de rader som värdet antas.\n",
    "\n",
    "Detta kallas också 'one-hot-encoding'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1455c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# För varje möjlig kategoriskt värde, loopa och konstruera en ny kolumn enligt ovan\n",
    "\n",
    "categorical_columns = ['reason']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    for value in set(students_df[column].values):\n",
    "    \n",
    "        onehotencode = [1 if x == value else 0 for x in students_df[column]]\n",
    "        students_df[value] = onehotencode\n",
    "    \n",
    "\n",
    "#slutligen, droppa orginalkolumnen som vi inte längre behöver    \n",
    "\n",
    "for column in categorical_columns:\n",
    "    students_df = students_df.drop(columns=[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cea04dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>higher</th>\n",
       "      <th>...</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>other</th>\n",
       "      <th>reputation</th>\n",
       "      <th>course</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex  age  famsize  Pstatus  Medu  Fedu  studytime  failures  \\\n",
       "0         1    1   18        1        1     4     4          2         0   \n",
       "1         1    1   17        1        0     1     1          2         0   \n",
       "2         1    1   15        0        0     1     1          2         0   \n",
       "3         1    1   15        1        0     4     2          3         0   \n",
       "4         1    1   16        1        0     3     3          2         0   \n",
       "..      ...  ...  ...      ...      ...   ...   ...        ...       ...   \n",
       "644       0    1   19        1        0     2     3          3         1   \n",
       "645       0    1   18        0        0     3     1          2         0   \n",
       "646       0    1   18        1        0     1     1          2         0   \n",
       "647       0    0   17        0        0     3     1          1         0   \n",
       "648       0    0   18        0        0     3     2          1         0   \n",
       "\n",
       "     higher  ...  Dalc  Walc  health  G1  G2  G3  other  reputation  course  \\\n",
       "0         1  ...     1     1       3   0  11  11      0           0       1   \n",
       "1         1  ...     1     1       3   9  11  11      0           0       1   \n",
       "2         1  ...     2     3       3  12  13  12      1           0       0   \n",
       "3         1  ...     1     1       5  14  14  14      0           0       0   \n",
       "4         1  ...     1     2       5  11  13  13      0           0       0   \n",
       "..      ...  ...   ...   ...     ...  ..  ..  ..    ...         ...     ...   \n",
       "644       1  ...     1     2       5  10  11  10      0           0       1   \n",
       "645       1  ...     1     1       1  15  15  16      0           0       1   \n",
       "646       1  ...     1     1       5  11  12   9      0           0       1   \n",
       "647       1  ...     3     4       2  10  10  10      0           0       1   \n",
       "648       1  ...     3     4       5  10  11  11      0           0       1   \n",
       "\n",
       "     home  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  \n",
       "..    ...  \n",
       "644     0  \n",
       "645     0  \n",
       "646     0  \n",
       "647     0  \n",
       "648     0  \n",
       "\n",
       "[649 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79f2eb",
   "metadata": {},
   "source": [
    "Nu ser det redan bättre ut!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed95b0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb150b30",
   "metadata": {},
   "source": [
    "Låt oss bara re-arrange så att slutbetyg-kolumnen (G3) är sista kolumnen i dataframet. Det blir lite lättare då."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19119ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = students_df.pop('G3') #droppa columnen från students_df, och fånga upp den i variablen g3\n",
    "students_df['G3'] = g3     #lägg tillbaks kolumnen. På detta sätt hamnar den på sista plats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf89f28",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26782979",
   "metadata": {},
   "source": [
    "Nu går vi vidare!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54455aba",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640886a",
   "metadata": {},
   "source": [
    "**5) skala data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c4c01c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 649 entries, 0 to 648\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   school      649 non-null    int64\n",
      " 1   sex         649 non-null    int64\n",
      " 2   age         649 non-null    int64\n",
      " 3   famsize     649 non-null    int64\n",
      " 4   Pstatus     649 non-null    int64\n",
      " 5   Medu        649 non-null    int64\n",
      " 6   Fedu        649 non-null    int64\n",
      " 7   studytime   649 non-null    int64\n",
      " 8   failures    649 non-null    int64\n",
      " 9   higher      649 non-null    int64\n",
      " 10  internet    649 non-null    int64\n",
      " 11  Dalc        649 non-null    int64\n",
      " 12  Walc        649 non-null    int64\n",
      " 13  health      649 non-null    int64\n",
      " 14  G1          649 non-null    int64\n",
      " 15  G2          649 non-null    int64\n",
      " 16  other       649 non-null    int64\n",
      " 17  reputation  649 non-null    int64\n",
      " 18  course      649 non-null    int64\n",
      " 19  home        649 non-null    int64\n",
      " 20  G3          649 non-null    int64\n",
      "dtypes: int64(21)\n",
      "memory usage: 106.6 KB\n"
     ]
    }
   ],
   "source": [
    "students_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbced00",
   "metadata": {},
   "source": [
    "Vi ser nu att samtliga kolumner är av rätt datatyp.\n",
    "\n",
    "Det som återstår är att *normalisera* **input** kolumnerna. Detta är **superviktigt** att göra när man tränar neurala nätverk, för att ingen enstaka kolumn ska dominera de övriga i storlek. I vårt fall är det inte så illa, eftersom att värdena bland alla input kolumner är mellan 0 och som högst 20. \n",
    "\n",
    "Men, vi normaliserar iaf - det är best practice.\n",
    "\n",
    "Detta kan göras på olika sätt, men vanligtvis innebär detta att man skalar om värdena i respektive kolumn till att vara mellan [0,1] eller [-1,1]. Det spelar egentligen inte särskilt stor roll vilken av dessa skalor man väljer, men jag brukar välja [0,1] för kolumner som bara ha positiva värden, och [-1,1] för kolumner som har både positiva och negativa värden.\n",
    "\n",
    "Eftersom att alla våra inputkolumner endast antar positiva värden, \n",
    "\n",
    "kan vi således försöka skala de till [0,1]. Ett enkelt knep för att åstadkomma detta är helt enkelt att dela varje kolumn på sitt högsta värde.\n",
    "\n",
    "OBS: Vi normaliserar **inte** vår target kolumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7b132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = students_df.columns[:-1]\n",
    "\n",
    "for feature in feature_columns:\n",
    "    \n",
    "    students_df[feature] = students_df[feature]/max(students_df[feature].values) #dela varje inputkolumn på sitt högsta värde\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf9afa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>higher</th>\n",
       "      <th>...</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>other</th>\n",
       "      <th>reputation</th>\n",
       "      <th>course</th>\n",
       "      <th>home</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  sex       age  famsize  Pstatus  Medu  Fedu  studytime  failures  \\\n",
       "0       1.0  1.0  0.818182      1.0      1.0  1.00  1.00       0.50  0.000000   \n",
       "1       1.0  1.0  0.772727      1.0      0.0  0.25  0.25       0.50  0.000000   \n",
       "2       1.0  1.0  0.681818      0.0      0.0  0.25  0.25       0.50  0.000000   \n",
       "3       1.0  1.0  0.681818      1.0      0.0  1.00  0.50       0.75  0.000000   \n",
       "4       1.0  1.0  0.727273      1.0      0.0  0.75  0.75       0.50  0.000000   \n",
       "..      ...  ...       ...      ...      ...   ...   ...        ...       ...   \n",
       "644     0.0  1.0  0.863636      1.0      0.0  0.50  0.75       0.75  0.333333   \n",
       "645     0.0  1.0  0.818182      0.0      0.0  0.75  0.25       0.50  0.000000   \n",
       "646     0.0  1.0  0.818182      1.0      0.0  0.25  0.25       0.50  0.000000   \n",
       "647     0.0  0.0  0.772727      0.0      0.0  0.75  0.25       0.25  0.000000   \n",
       "648     0.0  0.0  0.818182      0.0      0.0  0.75  0.50       0.25  0.000000   \n",
       "\n",
       "     higher  ...  Dalc  Walc  health        G1        G2  other  reputation  \\\n",
       "0       1.0  ...   0.2   0.2     0.6  0.000000  0.578947    0.0         0.0   \n",
       "1       1.0  ...   0.2   0.2     0.6  0.473684  0.578947    0.0         0.0   \n",
       "2       1.0  ...   0.4   0.6     0.6  0.631579  0.684211    1.0         0.0   \n",
       "3       1.0  ...   0.2   0.2     1.0  0.736842  0.736842    0.0         0.0   \n",
       "4       1.0  ...   0.2   0.4     1.0  0.578947  0.684211    0.0         0.0   \n",
       "..      ...  ...   ...   ...     ...       ...       ...    ...         ...   \n",
       "644     1.0  ...   0.2   0.4     1.0  0.526316  0.578947    0.0         0.0   \n",
       "645     1.0  ...   0.2   0.2     0.2  0.789474  0.789474    0.0         0.0   \n",
       "646     1.0  ...   0.2   0.2     1.0  0.578947  0.631579    0.0         0.0   \n",
       "647     1.0  ...   0.6   0.8     0.4  0.526316  0.526316    0.0         0.0   \n",
       "648     1.0  ...   0.6   0.8     1.0  0.526316  0.578947    0.0         0.0   \n",
       "\n",
       "     course  home  G3  \n",
       "0       1.0   0.0  11  \n",
       "1       1.0   0.0  11  \n",
       "2       0.0   0.0  12  \n",
       "3       0.0   1.0  14  \n",
       "4       0.0   1.0  13  \n",
       "..      ...   ...  ..  \n",
       "644     1.0   0.0  10  \n",
       "645     1.0   0.0  16  \n",
       "646     1.0   0.0   9  \n",
       "647     1.0   0.0  10  \n",
       "648     1.0   0.0  11  \n",
       "\n",
       "[649 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38926e4a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc74cf6b",
   "metadata": {},
   "source": [
    "Sista steget är att omvandla datan till ett format som är optimalt för PyTorch. Ett format som kallas för *tensor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cb9e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 21)\n",
      "torch.Size([649, 21])\n"
     ]
    }
   ],
   "source": [
    "training_set = torch.tensor(students_df.values).float()            #nu är allt klart, så vi anger detta som vår training_set\n",
    "\n",
    "#säkerställ att datasetet är av samma storlek\n",
    "\n",
    "print(students_df.shape)\n",
    "\n",
    "print(training_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1ba71dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  0.8182,  ...,  1.0000,  0.0000, 11.0000],\n",
       "        [ 1.0000,  1.0000,  0.7727,  ...,  1.0000,  0.0000, 11.0000],\n",
       "        [ 1.0000,  1.0000,  0.6818,  ...,  0.0000,  0.0000, 12.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  1.0000,  0.8182,  ...,  1.0000,  0.0000,  9.0000],\n",
       "        [ 0.0000,  0.0000,  0.7727,  ...,  1.0000,  0.0000, 10.0000],\n",
       "        [ 0.0000,  0.0000,  0.8182,  ...,  1.0000,  0.0000, 11.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set           # visualisera hela tensor-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62362a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 11., 12., 14., 13., 13., 13., 13., 17., 13., 14., 13., 12., 13.,\n",
       "        15., 17., 14., 14.,  7., 12., 14., 12., 14., 10., 10., 12., 12., 11.,\n",
       "        13., 12., 11., 15., 15., 12., 12., 11., 14., 13., 12., 12., 10., 11.,\n",
       "        15., 10., 11., 11., 13., 17., 13., 12., 13., 16.,  9., 12., 13., 12.,\n",
       "        15., 16., 14., 16., 16., 16., 10., 13., 12., 16., 12., 10., 11., 15.,\n",
       "        11., 10., 11., 14., 11., 11., 11., 13., 10., 11., 12.,  9., 11., 13.,\n",
       "        12., 12., 11., 15., 11., 10., 11., 13., 12., 14., 12., 13., 11., 12.,\n",
       "        13., 13.,  8., 16., 12., 10., 16., 10., 10., 14., 11., 14., 14., 11.,\n",
       "        10., 18., 10., 14., 16., 15., 11., 14., 14., 13., 13., 13., 11.,  9.,\n",
       "        11., 11., 15., 13., 12.,  8., 11., 13., 12., 14., 11., 11., 11., 15.,\n",
       "        10., 13., 12., 11., 11., 10., 10., 14.,  9., 11.,  9., 13., 11., 13.,\n",
       "        11.,  6., 12., 10., 11., 13., 11.,  8., 11.,  0., 10., 13., 11., 13.,\n",
       "         8., 10., 11., 11.,  1., 10.,  9.,  8., 10.,  8.,  8.,  8., 11., 18.,\n",
       "        13., 17., 10., 18., 10., 13., 15., 11., 14., 10., 11., 13., 11., 13.,\n",
       "        17., 14., 16., 14., 11., 16., 14., 10., 13., 12., 12., 10., 12., 16.,\n",
       "        14., 12., 16., 11., 15., 12., 15., 13., 13.,  8., 12., 15., 13., 12.,\n",
       "        12., 12., 13., 11., 11., 15., 10., 10., 13., 13., 11., 12., 14., 10.,\n",
       "        16.,  8., 17., 11., 11., 16., 12., 13., 13., 14.,  9., 12., 16., 10.,\n",
       "        13., 10., 10.,  7.,  8.,  9., 15., 10., 11., 13.,  8.,  8., 10., 15.,\n",
       "        14., 15., 12., 15., 15., 12., 15., 11., 10., 11., 16., 11., 13.,  5.,\n",
       "        10., 11.,  7., 10.,  6., 12., 13., 10., 13., 17., 11., 11., 14., 14.,\n",
       "        13., 14., 16., 10., 12., 12., 15., 11., 12., 13., 13.,  9., 16., 14.,\n",
       "        12., 14., 10., 12., 16., 13., 18., 15., 16., 12., 10., 12., 13., 15.,\n",
       "        10., 10., 11., 10., 13., 18., 13., 14., 14., 12., 18., 14., 15., 17.,\n",
       "        16., 18., 19., 15., 15., 13., 14., 17., 17., 15., 13.,  8., 16., 18.,\n",
       "        11., 15., 11., 11., 15., 14., 17., 17., 15., 17., 14., 10., 13., 14.,\n",
       "        17., 17., 13., 14., 11., 11.,  9., 10., 13., 10., 17., 15., 14., 13.,\n",
       "        17., 10., 13., 15., 11., 12., 10., 10., 15., 15., 12., 12., 14., 14.,\n",
       "        15., 15., 16., 13., 17., 14., 14., 17., 17., 14., 13., 15., 16., 11.,\n",
       "        13., 12., 12., 15., 17., 15., 17., 10., 15., 11., 18., 17., 14., 11.,\n",
       "        17., 10., 13., 11., 12., 10., 11., 17.,  9., 11., 11., 10.,  7., 14.,\n",
       "        11., 10.,  8., 12., 12., 16.,  0.,  9., 14.,  8., 11.,  9., 11.,  9.,\n",
       "        17., 13., 15., 11., 11.,  8.,  8.,  9., 15., 11., 13., 10., 11., 14.,\n",
       "        14., 12., 11.,  8., 11., 14., 13., 13., 12., 12., 16., 10., 11., 14.,\n",
       "         8., 11.,  8., 10., 10., 11.,  9., 11.,  8., 11., 10., 10.,  9., 10.,\n",
       "        10.,  9., 10., 10.,  9., 13., 14., 10., 14., 16.,  7., 13.,  9., 14.,\n",
       "        13., 11., 10., 10.,  9., 18., 17., 10.,  7.,  8.,  7., 10., 16., 15.,\n",
       "         8.,  0.,  8., 10.,  8.,  6.,  8., 16., 14., 10.,  9., 11.,  9., 10.,\n",
       "         8., 16., 12., 10., 14., 12., 11., 10., 11., 11., 12.,  8., 12.,  8.,\n",
       "        16., 11., 11., 18., 13., 13., 10., 12., 10., 13., 11., 10., 10., 13.,\n",
       "        10., 10., 12.,  0., 10.,  9.,  9.,  0.,  9.,  8.,  8.,  9.,  7., 10.,\n",
       "        10., 10., 11., 11., 10.,  9., 10.,  8.,  7.,  0., 11.,  8.,  0.,  8.,\n",
       "         9., 10.,  7., 14., 13., 14., 18., 17., 18.,  0., 11., 14., 14., 10.,\n",
       "        13.,  0., 10.,  0., 18., 12., 11., 12.,  0., 15., 11., 10., 12., 15.,\n",
       "        14., 18., 15., 13., 15., 13.,  9., 16.,  9., 10.,  0., 10., 12.,  9.,\n",
       "        17., 12.,  9., 14., 16.,  9., 19.,  0., 16.,  0.,  0., 15., 11., 10.,\n",
       "        10., 16.,  9., 10., 11.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[:,-1]     # precis som vanligt kan vi ex få sista kolumnen (vilket motsvarar vår target \n",
    "                       # slutbetyg i detta fall) genom denna query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41ada8",
   "metadata": {},
   "source": [
    "**Sådär, all done. Nu kan vi gå vidare!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7a167",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ddceb",
   "metadata": {},
   "source": [
    "# Skapa Neurons med PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75207972",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac154a1",
   "metadata": {},
   "source": [
    "Att skapa modeller med PyTorch görs allra oftast via klasser. Lyckligtvis är detta supersimpelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08070a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class neuron(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(neuron, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95018f71",
   "metadata": {},
   "source": [
    "Vår input size till modellen är ju alla våra features, och de har vi 20 st av. **Eller hur?!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02cf7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 20\n",
    "\n",
    "model = neuron(input_size) # initiera en instans av vår neuron-klass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b0968a",
   "metadata": {},
   "source": [
    "Vi kan se en summary av vår modell genom att kalla på den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4bfeaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neuron(\n",
       "  (fc): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44a590",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82abcac",
   "metadata": {},
   "source": [
    "Om vi vill kan vi direkt räkna ut antal parametrar genom följande kodsnutt\n",
    "\n",
    "**Fråga: varför är antalet parametrar som det är?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e11f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 21\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962fba9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422a8e0",
   "metadata": {},
   "source": [
    "Vi kan läsa av dessa parametrar direkt via model.parameters(), där de är lagrade\n",
    "\n",
    "Lägg märke till att sifforna är helt random inom intervallet [-1,1]. \n",
    "\n",
    "**För att kontrollera detta, testa att initiera om modellen ovan, och dra följande kodsnutt igen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e854694f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vikter\n",
      "Parameter containing:\n",
      "tensor([[ 0.1045, -0.0128,  0.0884, -0.0847, -0.1390,  0.1933, -0.0869,  0.2131,\n",
      "         -0.0108, -0.1041,  0.1823, -0.0652,  0.1793, -0.0854, -0.1952,  0.0789,\n",
      "         -0.0793,  0.1328,  0.1495,  0.2223]], requires_grad=True)\n",
      "\n",
      "bias\n",
      "Parameter containing:\n",
      "tensor([-0.1734], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights, bias = model.parameters()\n",
    "\n",
    "print('vikter')\n",
    "print(weights, end='\\n\\n')\n",
    "\n",
    "print('bias')\n",
    "print(bias, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1892c4e0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b8bfd",
   "metadata": {},
   "source": [
    "För att ge input till vår modell, och få en output gör man helt enkelt såhär:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8f7eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_student = training_set[0,:-1]      # ta den första studentens input features (första raden)\n",
    "sample_grade = training_set[0,-1]         # extrahera även den studentens slutbetyg\n",
    "\n",
    "model_prediction = model(sample_student)  # predicta ett slutbetyg med vår färskt initierade modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "259bcd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True grade            : 11.0\n",
      "Vår models predict    : 0.22490368783473969\n"
     ]
    }
   ],
   "source": [
    "print('True grade            :', sample_grade.item())\n",
    "print('Vår models predict    :', model_prediction.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf8ac0",
   "metadata": {},
   "source": [
    "Ha, katastrofalt fel! \n",
    "\n",
    "Sifforna är inte ens i närheten av nära, eller hur? :) \n",
    "\n",
    "Det är OK, för vi har inte börjat träna.\n",
    "\n",
    "Men nu är dags!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba870b6c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb4beb",
   "metadata": {},
   "source": [
    "## Träna med PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea04962",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81435d45",
   "metadata": {},
   "source": [
    "Vi väljer först en loss function. Eftersom att vi kör regression kan vi exempelvis välja Mean Absolute Error (MAE) loss - även mer tekniskt kallat för L1 Loss. \n",
    "\n",
    "Kom ihåg att det här kommer användas för att kvantifier avståndet mellan våra prediktions och det sanna värdet. Vi kommer alltså vilja minimera denna loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf9baf",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e046f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5de68",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af972fa",
   "metadata": {},
   "source": [
    "Vi väljer också en så kallad optimizer. Det är den här som kommer utföra själva gradient descent steget vi pratat om.\n",
    "\n",
    "Notera här att vi också lägger in en parameter kallad *lr*. Detta är learning rate vi också pratat om, och bestämmer hur stort steg varje gradient descent tar när den uppdaterar våra parametrar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae82c3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af2629bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr = 0.001) # observera att vi här visar vår optimizer vilka modellens parametrar är, \n",
    "                                                # så att den vet vad ska uppdatera "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786171d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb3c9b",
   "metadata": {},
   "source": [
    "Nu under träningens gång så kommer inte vi skicka in hela datasetet på en gång, utan vi skickar in ett par training samples åt gången. Antalet samples vi skickar in per iteration kallas för *batch size*. Varför varje sådan batch kommer vi att utföra gradient descent och uppdatera (träna) våra parametrar. Mer om detta längre ner.\n",
    "\n",
    "Vanliga batchsizes är typ mellan 16-128. Vi kan gott köra med 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75a26c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_set,                  # det är denna funktion som kommer ansvara för att leverera\n",
    "                              batch_size = 16,               # samples till modellen under träningens gång\n",
    "                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f1601",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d986b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff84bc0",
   "metadata": {},
   "source": [
    "**Lite mer om dataloader och bathsize:**\n",
    "\n",
    "När vi väljer batch_size = 16 så kommer den, för varje gång den blir kallad, att välja randomly 16 stycken training samples som den levererar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0c1f8",
   "metadata": {},
   "source": [
    "Vi kan också se hur en sådan här batch ser ut, samt den första training samplen ur den batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8e9aced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 21])\n",
      "\n",
      "tensor(16.)\n",
      "tensor([1.0000, 1.0000, 0.7727, 0.0000, 0.0000, 0.5000, 1.0000, 0.5000, 0.0000,\n",
      "        1.0000, 0.0000, 0.2000, 0.2000, 1.0000, 0.7368, 0.7895, 0.0000, 0.0000,\n",
      "        1.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    \n",
    "    print(batch.size(), end='\\n\\n') # visa storleken för hela den här batchen\n",
    "    \n",
    "    print(batch[0,-1])              # printa första training samples slutbetyg, i den här batchen\n",
    "    print(batch[0,:-1])             # printa alla feature kolumns för första training sample i den här batchen\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a55ed",
   "metadata": {},
   "source": [
    "Vi ser att det är totalt 16 rader (training samples) i batchen, och 21 kolumner. Den sista kolumnen i varje rad motsvarar slutbetyg, precis som tidigare - och övriga är våra input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96723d5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b23979",
   "metadata": {},
   "source": [
    "Hur många batches har dataloader till oss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6e185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea6199",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6923e1",
   "metadata": {},
   "source": [
    "Vi kan även, för tydlighetens skull, se antalet training samples i varenda sådan batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b8a88e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1.   Antal samples: 16\n",
      "Batch: 2.   Antal samples: 16\n",
      "Batch: 3.   Antal samples: 16\n",
      "Batch: 4.   Antal samples: 16\n",
      "Batch: 5.   Antal samples: 16\n",
      "Batch: 6.   Antal samples: 16\n",
      "Batch: 7.   Antal samples: 16\n",
      "Batch: 8.   Antal samples: 16\n",
      "Batch: 9.   Antal samples: 16\n",
      "Batch: 10.   Antal samples: 16\n",
      "Batch: 11.   Antal samples: 16\n",
      "Batch: 12.   Antal samples: 16\n",
      "Batch: 13.   Antal samples: 16\n",
      "Batch: 14.   Antal samples: 16\n",
      "Batch: 15.   Antal samples: 16\n",
      "Batch: 16.   Antal samples: 16\n",
      "Batch: 17.   Antal samples: 16\n",
      "Batch: 18.   Antal samples: 16\n",
      "Batch: 19.   Antal samples: 16\n",
      "Batch: 20.   Antal samples: 16\n",
      "Batch: 21.   Antal samples: 16\n",
      "Batch: 22.   Antal samples: 16\n",
      "Batch: 23.   Antal samples: 16\n",
      "Batch: 24.   Antal samples: 16\n",
      "Batch: 25.   Antal samples: 16\n",
      "Batch: 26.   Antal samples: 16\n",
      "Batch: 27.   Antal samples: 16\n",
      "Batch: 28.   Antal samples: 16\n",
      "Batch: 29.   Antal samples: 16\n",
      "Batch: 30.   Antal samples: 16\n",
      "Batch: 31.   Antal samples: 16\n",
      "Batch: 32.   Antal samples: 16\n",
      "Batch: 33.   Antal samples: 16\n",
      "Batch: 34.   Antal samples: 16\n",
      "Batch: 35.   Antal samples: 16\n",
      "Batch: 36.   Antal samples: 16\n",
      "Batch: 37.   Antal samples: 16\n",
      "Batch: 38.   Antal samples: 16\n",
      "Batch: 39.   Antal samples: 16\n",
      "Batch: 40.   Antal samples: 16\n",
      "Batch: 41.   Antal samples: 9\n"
     ]
    }
   ],
   "source": [
    "batch_nummer = 0\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    \n",
    "    batch_nummer += 1\n",
    "\n",
    "    print(f'Batch: {batch_nummer}.  ',f'Antal samples: {len(batch)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbccb2",
   "metadata": {},
   "source": [
    "Om vi summerar antalet samples som levererades totalt av våra 41 batches ovan blir det exakt 649 - vilket är storleken på vårt dataset. DataLoader kommer alltså leverera (efter en komplett for-loop) lika manga training samples som storleken på vårt dataset!\n",
    "\n",
    "Som vi ser försöker den ge 16 samples för varje batch, förutom den sista – eftersom att vi skulle överskrida storleken på vårt dataset. Räkna ihop antalet ovan, och jämför med len(training_set).\n",
    "\n",
    "**Viktigt begrepp**:\n",
    "\n",
    "En komplett for-loop genom DataLoader kallas för en **epoch**. \n",
    "\n",
    "Dvs, när vår modell fått träna på lika manga samples som storleken på vart dataset, så sager vi att modellen fått träna i en epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9c6e8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af033d66",
   "metadata": {},
   "source": [
    "**Nu kör vi hela träningsloopen**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906770b6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1174dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ändra inget av det här, förens du blir instruerad till det\n",
    "\n",
    "input_size = 20                       \n",
    "batch_size = 16\n",
    "\n",
    "epochs = 100               # antal loopar genom dataloader vi låter vår modell träna på vårt dataset.\n",
    "learning_rate = 0.001      # hur stora steg gradient descent tar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55113b1",
   "metadata": {},
   "source": [
    "Som ni ser i träningskoden nedan är värdet på epochs antal gånger som vi kommer gå igenom datan i vår train_dataloader. \n",
    "\n",
    "Eftersom att vår train_dataloader innehar 41 batches, så kommer vi totalt att låta algoritmen gå igenom (41 x epochs) batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ca8c055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.165\n",
      "13.335\n",
      "10.609\n",
      "13.04\n",
      "13.347\n",
      "13.134\n",
      "13.017\n",
      "12.231\n",
      "11.897\n",
      "13.016\n",
      "12.379\n",
      "11.917\n",
      "12.732\n",
      "12.004\n",
      "13.136\n",
      "11.699\n",
      "12.376\n",
      "12.821\n",
      "12.589\n",
      "12.393\n",
      "12.399\n",
      "12.945\n",
      "12.844\n",
      "12.688\n",
      "10.632\n",
      "12.91\n",
      "11.09\n",
      "11.867\n",
      "12.425\n",
      "12.852\n",
      "11.932\n",
      "10.014\n",
      "11.667\n",
      "11.649\n",
      "13.362\n",
      "12.191\n",
      "12.922\n",
      "13.126\n",
      "11.018\n",
      "12.574\n",
      "12.927\n",
      "11.43\n",
      "12.331\n",
      "12.936\n",
      "11.93\n",
      "11.791\n",
      "12.079\n",
      "12.765\n",
      "11.084\n",
      "11.5\n",
      "10.275\n",
      "10.849\n",
      "12.476\n",
      "11.768\n",
      "11.707\n",
      "13.784\n",
      "12.939\n",
      "11.621\n",
      "12.379\n",
      "13.325\n",
      "12.43\n",
      "10.939\n",
      "12.73\n",
      "12.926\n",
      "12.547\n",
      "11.349\n",
      "11.719\n",
      "11.935\n",
      "12.207\n",
      "13.636\n",
      "11.915\n",
      "12.469\n",
      "11.645\n",
      "11.743\n",
      "13.361\n",
      "10.614\n",
      "11.732\n",
      "13.242\n",
      "11.467\n",
      "12.098\n",
      "12.623\n",
      "10.885\n",
      "11.785\n",
      "11.117\n",
      "12.82\n",
      "11.701\n",
      "11.252\n",
      "12.363\n",
      "12.809\n",
      "11.124\n",
      "12.612\n",
      "10.433\n",
      "12.539\n",
      "12.389\n",
      "11.972\n",
      "11.439\n",
      "11.364\n",
      "10.538\n",
      "12.475\n",
      "12.233\n",
      "10.888\n",
      "13.306\n",
      "11.481\n",
      "11.724\n",
      "11.782\n",
      "9.966\n",
      "12.068\n",
      "12.127\n",
      "12.963\n",
      "12.787\n",
      "12.291\n",
      "12.15\n",
      "10.858\n",
      "11.888\n",
      "11.866\n",
      "11.963\n",
      "11.952\n",
      "11.646\n",
      "12.373\n",
      "11.754\n",
      "12.571\n",
      "10.104\n",
      "11.664\n",
      "12.534\n",
      "11.624\n",
      "11.438\n",
      "11.378\n",
      "11.994\n",
      "11.773\n",
      "12.757\n",
      "10.19\n",
      "11.926\n",
      "12.522\n",
      "11.539\n",
      "12.04\n",
      "11.537\n",
      "11.664\n",
      "11.046\n",
      "10.446\n",
      "10.173\n",
      "12.413\n",
      "11.21\n",
      "11.913\n",
      "11.052\n",
      "10.514\n",
      "11.467\n",
      "11.676\n",
      "11.608\n",
      "12.145\n",
      "11.828\n",
      "11.436\n",
      "12.052\n",
      "11.381\n",
      "12.381\n",
      "11.274\n",
      "11.189\n",
      "11.142\n",
      "12.094\n",
      "12.833\n",
      "11.373\n",
      "11.683\n",
      "12.189\n",
      "10.744\n",
      "10.332\n",
      "11.388\n",
      "11.363\n",
      "11.21\n",
      "11.147\n",
      "11.37\n",
      "10.556\n",
      "11.117\n",
      "10.838\n",
      "12.065\n",
      "11.934\n",
      "12.876\n",
      "11.611\n",
      "11.343\n",
      "11.206\n",
      "12.09\n",
      "12.27\n",
      "10.846\n",
      "11.436\n",
      "11.678\n",
      "11.561\n",
      "9.82\n",
      "12.964\n",
      "11.501\n",
      "11.065\n",
      "11.9\n",
      "9.61\n",
      "11.343\n",
      "10.293\n",
      "9.893\n",
      "12.106\n",
      "10.289\n",
      "10.863\n",
      "10.284\n",
      "10.647\n",
      "12.295\n",
      "12.713\n",
      "12.284\n",
      "9.899\n",
      "11.607\n",
      "12.381\n",
      "11.438\n",
      "11.357\n",
      "11.747\n",
      "11.438\n",
      "11.005\n",
      "11.276\n",
      "10.863\n",
      "10.468\n",
      "11.49\n",
      "11.431\n",
      "10.523\n",
      "11.387\n",
      "11.644\n",
      "10.204\n",
      "10.854\n",
      "12.418\n",
      "9.32\n",
      "11.774\n",
      "11.565\n",
      "10.742\n",
      "11.047\n",
      "12.41\n",
      "11.26\n",
      "11.058\n",
      "9.919\n",
      "11.364\n",
      "11.212\n",
      "11.853\n",
      "10.565\n",
      "10.847\n",
      "11.537\n",
      "11.128\n",
      "12.624\n",
      "10.152\n",
      "11.11\n",
      "10.862\n",
      "11.71\n",
      "10.997\n",
      "10.435\n",
      "10.14\n",
      "10.884\n",
      "10.014\n",
      "9.46\n",
      "10.79\n",
      "10.332\n",
      "12.018\n",
      "10.45\n",
      "10.976\n",
      "10.191\n",
      "10.627\n",
      "10.599\n",
      "10.373\n",
      "11.113\n",
      "9.939\n",
      "11.036\n",
      "11.367\n",
      "11.293\n",
      "11.49\n",
      "10.331\n",
      "11.649\n",
      "10.375\n",
      "10.793\n",
      "10.349\n",
      "11.709\n",
      "12.074\n",
      "10.05\n",
      "10.713\n",
      "12.023\n",
      "10.947\n",
      "11.086\n",
      "12.048\n",
      "10.427\n",
      "10.235\n",
      "9.721\n",
      "11.812\n",
      "10.824\n",
      "10.537\n",
      "11.311\n",
      "11.633\n",
      "11.821\n",
      "11.552\n",
      "8.427\n",
      "10.502\n",
      "11.051\n",
      "10.698\n",
      "10.559\n",
      "12.034\n",
      "11.135\n",
      "10.477\n",
      "10.699\n",
      "10.399\n",
      "8.713\n",
      "11.219\n",
      "10.847\n",
      "10.576\n",
      "10.466\n",
      "10.657\n",
      "10.628\n",
      "10.674\n",
      "10.297\n",
      "10.722\n",
      "9.708\n",
      "9.083\n",
      "10.519\n",
      "11.077\n",
      "9.942\n",
      "10.023\n",
      "11.659\n",
      "9.646\n",
      "10.891\n",
      "10.672\n",
      "11.356\n",
      "10.225\n",
      "10.079\n",
      "11.501\n",
      "10.248\n",
      "11.387\n",
      "11.515\n",
      "10.6\n",
      "10.748\n",
      "10.252\n",
      "10.772\n",
      "10.436\n",
      "11.477\n",
      "11.281\n",
      "9.816\n",
      "10.63\n",
      "10.122\n",
      "10.286\n",
      "10.328\n",
      "10.625\n",
      "11.083\n",
      "10.938\n",
      "10.241\n",
      "11.69\n",
      "10.185\n",
      "10.63\n",
      "10.475\n",
      "10.591\n",
      "10.447\n",
      "10.3\n",
      "9.689\n",
      "10.479\n",
      "10.092\n",
      "11.353\n",
      "8.931\n",
      "9.884\n",
      "9.978\n",
      "8.899\n",
      "10.505\n",
      "11.009\n",
      "9.85\n",
      "11.053\n",
      "10.096\n",
      "10.536\n",
      "10.329\n",
      "10.335\n",
      "9.802\n",
      "11.445\n",
      "10.259\n",
      "11.354\n",
      "10.393\n",
      "9.285\n",
      "10.024\n",
      "9.868\n",
      "9.354\n",
      "9.914\n",
      "9.441\n",
      "10.992\n",
      "9.169\n",
      "10.35\n",
      "10.956\n",
      "9.778\n",
      "10.393\n",
      "11.397\n",
      "10.538\n",
      "11.055\n",
      "10.458\n",
      "10.294\n",
      "10.56\n",
      "9.849\n",
      "9.498\n",
      "9.591\n",
      "11.003\n",
      "9.888\n",
      "9.513\n",
      "10.848\n",
      "8.72\n",
      "10.551\n",
      "10.085\n",
      "11.108\n",
      "9.73\n",
      "9.163\n",
      "10.728\n",
      "10.086\n",
      "10.361\n",
      "10.304\n",
      "8.934\n",
      "9.286\n",
      "9.574\n",
      "10.44\n",
      "10.782\n",
      "10.4\n",
      "9.697\n",
      "9.956\n",
      "11.174\n",
      "9.903\n",
      "10.563\n",
      "10.197\n",
      "10.47\n",
      "9.609\n",
      "9.67\n",
      "10.274\n",
      "10.709\n",
      "8.777\n",
      "8.607\n",
      "10.434\n",
      "9.626\n",
      "9.703\n",
      "10.314\n",
      "9.948\n",
      "9.023\n",
      "9.495\n",
      "11.325\n",
      "9.464\n",
      "9.978\n",
      "10.008\n",
      "9.653\n",
      "9.822\n",
      "10.759\n",
      "9.066\n",
      "8.917\n",
      "10.835\n",
      "9.477\n",
      "9.895\n",
      "11.184\n",
      "9.073\n",
      "9.999\n",
      "10.023\n",
      "9.855\n",
      "10.648\n",
      "11.0\n",
      "9.635\n",
      "10.174\n",
      "8.786\n",
      "9.47\n",
      "8.444\n",
      "10.478\n",
      "10.124\n",
      "10.399\n",
      "8.329\n",
      "9.437\n",
      "10.485\n",
      "10.127\n",
      "9.626\n",
      "9.737\n",
      "8.459\n",
      "9.538\n",
      "9.686\n",
      "9.181\n",
      "10.607\n",
      "10.214\n",
      "9.158\n",
      "8.68\n",
      "9.922\n",
      "9.548\n",
      "9.506\n",
      "9.044\n",
      "10.51\n",
      "10.189\n",
      "9.305\n",
      "8.22\n",
      "9.92\n",
      "9.077\n",
      "10.014\n",
      "9.313\n",
      "9.403\n",
      "9.463\n",
      "9.403\n",
      "10.636\n",
      "10.059\n",
      "9.353\n",
      "9.061\n",
      "9.855\n",
      "10.572\n",
      "8.573\n",
      "10.667\n",
      "9.816\n",
      "8.659\n",
      "9.723\n",
      "9.302\n",
      "10.335\n",
      "9.39\n",
      "8.102\n",
      "10.14\n",
      "9.7\n",
      "9.815\n",
      "9.604\n",
      "8.813\n",
      "9.414\n",
      "9.141\n",
      "10.313\n",
      "8.882\n",
      "8.866\n",
      "9.85\n",
      "9.807\n",
      "8.095\n",
      "8.596\n",
      "8.183\n",
      "10.116\n",
      "9.842\n",
      "9.014\n",
      "9.994\n",
      "10.01\n",
      "9.509\n",
      "8.715\n",
      "10.449\n",
      "9.189\n",
      "10.443\n",
      "8.99\n",
      "9.566\n",
      "8.853\n",
      "9.654\n",
      "9.481\n",
      "9.077\n",
      "9.96\n",
      "9.863\n",
      "9.274\n",
      "8.687\n",
      "8.964\n",
      "10.001\n",
      "9.457\n",
      "9.19\n",
      "9.851\n",
      "8.187\n",
      "9.75\n",
      "8.692\n",
      "9.833\n",
      "8.439\n",
      "8.232\n",
      "9.368\n",
      "8.51\n",
      "7.886\n",
      "9.262\n",
      "9.493\n",
      "9.035\n",
      "9.45\n",
      "8.258\n",
      "10.475\n",
      "8.956\n",
      "9.128\n",
      "8.807\n",
      "9.733\n",
      "11.093\n",
      "8.873\n",
      "9.343\n",
      "8.456\n",
      "9.772\n",
      "9.702\n",
      "9.061\n",
      "8.719\n",
      "10.181\n",
      "8.435\n",
      "8.751\n",
      "9.512\n",
      "10.207\n",
      "8.413\n",
      "8.757\n",
      "8.393\n",
      "9.141\n",
      "9.422\n",
      "8.349\n",
      "9.496\n",
      "7.634\n",
      "8.883\n",
      "9.896\n",
      "8.888\n",
      "8.891\n",
      "9.009\n",
      "8.966\n",
      "8.867\n",
      "8.565\n",
      "9.176\n",
      "9.053\n",
      "8.215\n",
      "8.805\n",
      "9.496\n",
      "9.312\n",
      "8.732\n",
      "8.671\n",
      "8.647\n",
      "8.746\n",
      "8.93\n",
      "9.185\n",
      "9.176\n",
      "7.577\n",
      "8.898\n",
      "9.576\n",
      "9.691\n",
      "9.576\n",
      "9.056\n",
      "8.339\n",
      "8.58\n",
      "9.578\n",
      "9.056\n",
      "9.174\n",
      "8.712\n",
      "9.3\n",
      "8.705\n",
      "8.88\n",
      "7.543\n",
      "9.123\n",
      "9.557\n",
      "8.509\n",
      "9.156\n",
      "7.749\n",
      "9.008\n",
      "8.413\n",
      "8.716\n",
      "8.699\n",
      "8.129\n",
      "7.916\n",
      "9.185\n",
      "7.99\n",
      "9.087\n",
      "9.58\n",
      "9.216\n",
      "8.507\n",
      "8.484\n",
      "8.28\n",
      "8.026\n",
      "8.759\n",
      "8.672\n",
      "9.118\n",
      "9.645\n",
      "9.242\n",
      "8.469\n",
      "9.024\n",
      "6.75\n",
      "8.155\n",
      "8.251\n",
      "8.351\n",
      "8.915\n",
      "9.605\n",
      "7.8\n",
      "7.534\n",
      "8.841\n",
      "8.863\n",
      "10.072\n",
      "9.241\n",
      "8.383\n",
      "9.048\n",
      "9.152\n",
      "7.77\n",
      "6.312\n",
      "8.452\n",
      "7.407\n",
      "8.173\n",
      "8.73\n",
      "8.692\n",
      "8.079\n",
      "7.671\n",
      "8.135\n",
      "9.207\n",
      "8.416\n",
      "8.661\n",
      "8.814\n",
      "9.471\n",
      "8.021\n",
      "8.2\n",
      "8.972\n",
      "7.268\n",
      "8.745\n",
      "9.344\n",
      "9.013\n",
      "8.466\n",
      "8.284\n",
      "9.341\n",
      "7.836\n",
      "8.468\n",
      "8.188\n",
      "8.741\n",
      "9.64\n",
      "8.322\n",
      "7.659\n",
      "8.815\n",
      "8.512\n",
      "9.106\n",
      "8.428\n",
      "8.843\n",
      "8.316\n",
      "8.317\n",
      "7.748\n",
      "7.901\n",
      "7.89\n",
      "8.688\n",
      "8.369\n",
      "8.033\n",
      "8.151\n",
      "7.625\n",
      "8.654\n",
      "7.392\n",
      "8.641\n",
      "8.164\n",
      "8.487\n",
      "8.686\n",
      "9.667\n",
      "7.996\n",
      "9.267\n",
      "8.641\n",
      "7.883\n",
      "9.903\n",
      "8.322\n",
      "7.864\n",
      "8.593\n",
      "7.748\n",
      "7.621\n",
      "6.965\n",
      "7.724\n",
      "7.167\n",
      "7.731\n",
      "7.447\n",
      "8.175\n",
      "8.28\n",
      "8.95\n",
      "8.399\n",
      "7.574\n",
      "8.76\n",
      "8.528\n",
      "8.987\n",
      "7.997\n",
      "7.198\n",
      "8.119\n",
      "7.876\n",
      "8.463\n",
      "7.669\n",
      "7.705\n",
      "7.508\n",
      "7.6\n",
      "8.056\n",
      "7.935\n",
      "7.249\n",
      "7.172\n",
      "7.204\n",
      "8.156\n",
      "8.833\n",
      "8.556\n",
      "8.156\n",
      "8.557\n",
      "7.584\n",
      "7.317\n",
      "7.735\n",
      "7.993\n",
      "7.821\n",
      "8.5\n",
      "7.432\n",
      "7.892\n",
      "7.301\n",
      "8.437\n",
      "8.171\n",
      "7.85\n",
      "8.003\n",
      "8.221\n",
      "7.487\n",
      "7.544\n",
      "8.682\n",
      "7.677\n",
      "8.214\n",
      "8.299\n",
      "8.786\n",
      "8.349\n",
      "8.4\n",
      "8.295\n",
      "7.675\n",
      "7.585\n",
      "9.108\n",
      "7.199\n",
      "8.458\n",
      "7.364\n",
      "8.255\n",
      "6.932\n",
      "7.442\n",
      "7.338\n",
      "8.209\n",
      "7.272\n",
      "7.404\n",
      "7.3\n",
      "9.391\n",
      "8.015\n",
      "7.121\n",
      "7.158\n",
      "7.405\n",
      "6.817\n",
      "8.051\n",
      "7.074\n",
      "7.413\n",
      "8.59\n",
      "8.708\n",
      "7.941\n",
      "7.295\n",
      "6.612\n",
      "8.004\n",
      "6.953\n",
      "8.693\n",
      "7.444\n",
      "7.929\n",
      "8.049\n",
      "7.607\n",
      "6.41\n",
      "8.124\n",
      "7.834\n",
      "7.767\n",
      "7.863\n",
      "7.313\n",
      "8.559\n",
      "7.848\n",
      "7.471\n",
      "8.193\n",
      "7.459\n",
      "8.776\n",
      "8.528\n",
      "8.18\n",
      "7.781\n",
      "7.563\n",
      "7.545\n",
      "6.791\n",
      "7.225\n",
      "7.401\n",
      "7.824\n",
      "7.261\n",
      "8.108\n",
      "7.996\n",
      "7.712\n",
      "8.308\n",
      "5.706\n",
      "6.914\n",
      "8.203\n",
      "7.108\n",
      "7.245\n",
      "6.555\n",
      "7.625\n",
      "6.974\n",
      "7.261\n",
      "7.466\n",
      "7.868\n",
      "7.941\n",
      "6.801\n",
      "7.374\n",
      "9.188\n",
      "7.664\n",
      "6.454\n",
      "7.002\n",
      "7.096\n",
      "6.9\n",
      "7.418\n",
      "6.762\n",
      "6.228\n",
      "7.565\n",
      "7.088\n",
      "7.346\n",
      "8.65\n",
      "6.559\n",
      "6.536\n",
      "7.298\n",
      "7.245\n",
      "6.706\n",
      "6.948\n",
      "8.242\n",
      "7.261\n",
      "7.85\n",
      "6.425\n",
      "6.807\n",
      "7.313\n",
      "6.995\n",
      "7.514\n",
      "6.3\n",
      "8.037\n",
      "7.872\n",
      "7.751\n",
      "7.555\n",
      "6.761\n",
      "7.358\n",
      "8.182\n",
      "7.875\n",
      "7.174\n",
      "6.721\n",
      "7.139\n",
      "7.15\n",
      "6.755\n",
      "7.174\n",
      "7.725\n",
      "7.119\n",
      "7.673\n",
      "5.824\n",
      "5.893\n",
      "6.874\n",
      "7.957\n",
      "7.465\n",
      "7.814\n",
      "6.695\n",
      "6.865\n",
      "7.717\n",
      "7.702\n",
      "8.324\n",
      "6.864\n",
      "6.918\n",
      "6.435\n",
      "6.941\n",
      "7.959\n",
      "7.16\n",
      "6.814\n",
      "6.076\n",
      "6.822\n",
      "7.761\n",
      "6.969\n",
      "7.666\n",
      "7.939\n",
      "6.576\n",
      "7.467\n",
      "6.583\n",
      "7.724\n",
      "6.127\n",
      "6.444\n",
      "6.887\n",
      "6.631\n",
      "7.414\n",
      "7.697\n",
      "6.532\n",
      "5.96\n",
      "6.327\n",
      "6.342\n",
      "7.47\n",
      "6.884\n",
      "7.516\n",
      "6.78\n",
      "6.857\n",
      "6.617\n",
      "6.448\n",
      "5.174\n",
      "6.889\n",
      "7.105\n",
      "6.698\n",
      "7.54\n",
      "6.365\n",
      "6.213\n",
      "6.211\n",
      "6.799\n",
      "7.489\n",
      "6.883\n",
      "7.082\n",
      "6.41\n",
      "5.694\n",
      "6.903\n",
      "7.581\n",
      "6.649\n",
      "5.617\n",
      "6.069\n",
      "7.135\n",
      "6.545\n",
      "7.299\n",
      "5.734\n",
      "7.485\n",
      "6.956\n",
      "6.439\n",
      "6.881\n",
      "6.889\n",
      "8.239\n",
      "7.031\n",
      "6.083\n",
      "6.764\n",
      "6.881\n",
      "6.032\n",
      "8.023\n",
      "5.485\n",
      "6.591\n",
      "6.185\n",
      "7.485\n",
      "6.639\n",
      "7.332\n",
      "6.454\n",
      "6.039\n",
      "7.373\n",
      "5.804\n",
      "6.933\n",
      "7.284\n",
      "6.836\n",
      "6.744\n",
      "7.041\n",
      "5.858\n",
      "7.242\n",
      "5.863\n",
      "5.632\n",
      "6.152\n",
      "6.35\n",
      "6.327\n",
      "6.54\n",
      "6.767\n",
      "6.808\n",
      "6.477\n",
      "6.748\n",
      "6.395\n",
      "6.296\n",
      "6.983\n",
      "6.662\n",
      "6.38\n",
      "6.101\n",
      "6.016\n",
      "7.408\n",
      "7.702\n",
      "5.859\n",
      "6.63\n",
      "6.623\n",
      "7.056\n",
      "6.672\n",
      "5.835\n",
      "6.07\n",
      "6.689\n",
      "6.58\n",
      "6.179\n",
      "6.06\n",
      "5.784\n",
      "6.302\n",
      "6.667\n",
      "6.323\n",
      "6.415\n",
      "6.079\n",
      "6.116\n",
      "7.007\n",
      "5.724\n",
      "5.276\n",
      "7.232\n",
      "6.389\n",
      "6.094\n",
      "6.316\n",
      "5.841\n",
      "5.486\n",
      "6.944\n",
      "6.584\n",
      "6.027\n",
      "6.995\n",
      "5.892\n",
      "6.648\n",
      "5.449\n",
      "7.013\n",
      "6.447\n",
      "6.218\n",
      "5.969\n",
      "5.712\n",
      "6.823\n",
      "7.214\n",
      "5.85\n",
      "6.967\n",
      "4.768\n",
      "5.593\n",
      "7.156\n",
      "6.082\n",
      "6.917\n",
      "6.31\n",
      "6.011\n",
      "6.686\n",
      "5.358\n",
      "6.342\n",
      "5.953\n",
      "5.855\n",
      "6.063\n",
      "4.581\n",
      "7.257\n",
      "5.794\n",
      "5.744\n",
      "5.502\n",
      "5.131\n",
      "6.451\n",
      "6.58\n",
      "6.185\n",
      "6.097\n",
      "6.564\n",
      "5.848\n",
      "5.626\n",
      "5.574\n",
      "6.128\n",
      "5.998\n",
      "5.639\n",
      "5.958\n",
      "6.702\n",
      "6.576\n",
      "6.226\n",
      "5.467\n",
      "6.02\n",
      "6.743\n",
      "5.819\n",
      "5.718\n",
      "6.185\n",
      "6.565\n",
      "6.886\n",
      "6.354\n",
      "5.478\n",
      "5.843\n",
      "5.546\n",
      "5.989\n",
      "6.233\n",
      "6.348\n",
      "6.477\n",
      "6.253\n",
      "6.001\n",
      "5.922\n",
      "5.941\n",
      "5.752\n",
      "6.584\n",
      "6.25\n",
      "6.51\n",
      "5.225\n",
      "5.744\n",
      "5.763\n",
      "6.239\n",
      "5.89\n",
      "5.224\n",
      "5.917\n",
      "5.989\n",
      "5.359\n",
      "5.333\n",
      "6.498\n",
      "6.074\n",
      "6.54\n",
      "6.233\n",
      "5.43\n",
      "4.636\n",
      "4.773\n",
      "5.221\n",
      "6.898\n",
      "5.732\n",
      "7.146\n",
      "6.212\n",
      "4.718\n",
      "5.23\n",
      "5.293\n",
      "6.533\n",
      "6.555\n",
      "5.744\n",
      "5.324\n",
      "5.408\n",
      "3.996\n",
      "6.725\n",
      "6.327\n",
      "5.033\n",
      "5.45\n",
      "5.127\n",
      "5.664\n",
      "6.102\n",
      "6.526\n",
      "5.67\n",
      "5.218\n",
      "5.507\n",
      "6.294\n",
      "5.419\n",
      "4.782\n",
      "5.284\n",
      "6.982\n",
      "4.992\n",
      "4.956\n",
      "6.5\n",
      "5.133\n",
      "5.542\n",
      "6.477\n",
      "5.886\n",
      "5.235\n",
      "7.155\n",
      "4.19\n",
      "6.065\n",
      "6.098\n",
      "5.033\n",
      "5.676\n",
      "5.125\n",
      "5.219\n",
      "5.463\n",
      "5.027\n",
      "5.219\n",
      "5.33\n",
      "5.59\n",
      "4.958\n",
      "6.254\n",
      "5.163\n",
      "5.79\n",
      "5.291\n",
      "5.559\n",
      "6.348\n",
      "4.175\n",
      "4.889\n",
      "5.58\n",
      "5.921\n",
      "5.094\n",
      "4.971\n",
      "5.583\n",
      "5.671\n",
      "5.293\n",
      "4.547\n",
      "6.232\n",
      "5.362\n",
      "4.977\n",
      "5.838\n",
      "5.864\n",
      "6.674\n",
      "5.151\n",
      "5.111\n",
      "6.191\n",
      "4.927\n",
      "6.112\n",
      "4.91\n",
      "5.593\n",
      "4.723\n",
      "5.413\n",
      "5.332\n",
      "6.01\n",
      "4.929\n",
      "4.671\n",
      "5.644\n",
      "5.934\n",
      "4.909\n",
      "5.863\n",
      "5.248\n",
      "4.646\n",
      "5.071\n",
      "5.525\n",
      "5.764\n",
      "6.036\n",
      "4.008\n",
      "5.118\n",
      "5.173\n",
      "4.844\n",
      "4.115\n",
      "5.317\n",
      "6.122\n",
      "5.637\n",
      "4.005\n",
      "5.618\n",
      "5.341\n",
      "4.935\n",
      "3.966\n",
      "5.089\n",
      "6.053\n",
      "5.644\n",
      "4.85\n",
      "5.925\n",
      "5.182\n",
      "4.974\n",
      "5.657\n",
      "5.825\n",
      "4.519\n",
      "4.531\n",
      "5.196\n",
      "5.824\n",
      "4.822\n",
      "5.7\n",
      "4.941\n",
      "4.189\n",
      "5.61\n",
      "3.972\n",
      "5.087\n",
      "5.778\n",
      "4.432\n",
      "5.185\n",
      "5.725\n",
      "5.029\n",
      "5.333\n",
      "4.378\n",
      "5.857\n",
      "5.063\n",
      "5.705\n",
      "5.527\n",
      "6.035\n",
      "4.206\n",
      "4.345\n",
      "4.58\n",
      "5.234\n",
      "4.483\n",
      "5.424\n",
      "4.807\n",
      "4.16\n",
      "5.156\n",
      "4.588\n",
      "4.388\n",
      "5.127\n",
      "4.654\n",
      "5.066\n",
      "5.004\n",
      "4.716\n",
      "5.553\n",
      "5.27\n",
      "5.93\n",
      "5.369\n",
      "4.869\n",
      "5.67\n",
      "5.51\n",
      "4.781\n",
      "5.901\n",
      "4.354\n",
      "4.677\n",
      "4.127\n",
      "4.689\n",
      "4.725\n",
      "5.714\n",
      "4.329\n",
      "4.682\n",
      "4.004\n",
      "4.061\n",
      "4.465\n",
      "5.26\n",
      "4.988\n",
      "6.587\n",
      "5.234\n",
      "5.67\n",
      "3.946\n",
      "4.599\n",
      "5.629\n",
      "4.37\n",
      "5.033\n",
      "4.255\n",
      "5.074\n",
      "4.157\n",
      "5.056\n",
      "4.554\n",
      "5.454\n",
      "4.1\n",
      "4.745\n",
      "4.786\n",
      "4.001\n",
      "4.365\n",
      "4.729\n",
      "5.151\n",
      "4.933\n",
      "4.929\n",
      "5.199\n",
      "4.029\n",
      "5.42\n",
      "4.829\n",
      "3.941\n",
      "4.452\n",
      "3.745\n",
      "5.241\n",
      "4.287\n",
      "4.564\n",
      "5.284\n",
      "4.91\n",
      "4.241\n",
      "5.677\n",
      "4.444\n",
      "5.407\n",
      "4.281\n",
      "4.666\n",
      "4.594\n",
      "4.895\n",
      "3.336\n",
      "4.565\n",
      "4.863\n",
      "4.764\n",
      "5.209\n",
      "4.406\n",
      "3.814\n",
      "4.493\n",
      "4.361\n",
      "4.845\n",
      "4.37\n",
      "5.727\n",
      "4.185\n",
      "5.002\n",
      "4.748\n",
      "4.526\n",
      "3.874\n",
      "4.349\n",
      "5.142\n",
      "4.242\n",
      "4.987\n",
      "4.656\n",
      "4.909\n",
      "4.43\n",
      "4.489\n",
      "4.86\n",
      "4.655\n",
      "4.95\n",
      "3.992\n",
      "5.106\n",
      "3.607\n",
      "4.619\n",
      "5.711\n",
      "3.816\n",
      "3.972\n",
      "4.115\n",
      "4.583\n",
      "3.248\n",
      "4.886\n",
      "4.539\n",
      "3.952\n",
      "4.094\n",
      "4.173\n",
      "4.096\n",
      "4.456\n",
      "3.711\n",
      "4.566\n",
      "4.479\n",
      "5.011\n",
      "4.347\n",
      "4.038\n",
      "4.23\n",
      "5.357\n",
      "4.497\n",
      "4.72\n",
      "4.911\n",
      "3.892\n",
      "4.955\n",
      "3.425\n",
      "3.936\n",
      "4.532\n",
      "5.241\n",
      "4.803\n",
      "4.502\n",
      "3.127\n",
      "4.242\n",
      "4.522\n",
      "4.544\n",
      "4.238\n",
      "4.281\n",
      "4.621\n",
      "3.753\n",
      "4.817\n",
      "4.668\n",
      "4.021\n",
      "4.885\n",
      "3.729\n",
      "3.94\n",
      "3.408\n",
      "4.845\n",
      "5.444\n",
      "4.222\n",
      "5.125\n",
      "5.075\n",
      "3.643\n",
      "3.613\n",
      "4.461\n",
      "2.679\n",
      "4.074\n",
      "4.885\n",
      "3.898\n",
      "4.09\n",
      "4.403\n",
      "3.247\n",
      "3.4\n",
      "3.494\n",
      "3.834\n",
      "2.91\n",
      "4.807\n",
      "4.107\n",
      "5.05\n",
      "3.371\n",
      "4.849\n",
      "4.5\n",
      "4.782\n",
      "4.057\n",
      "4.312\n",
      "4.232\n",
      "3.518\n",
      "3.117\n",
      "5.51\n",
      "3.878\n",
      "4.578\n",
      "4.405\n",
      "3.868\n",
      "4.462\n",
      "5.212\n",
      "4.398\n",
      "4.357\n",
      "4.469\n",
      "4.453\n",
      "3.869\n",
      "3.59\n",
      "3.308\n",
      "4.562\n",
      "3.183\n",
      "4.285\n",
      "3.353\n",
      "4.152\n",
      "4.008\n",
      "3.919\n",
      "3.958\n",
      "4.519\n",
      "3.802\n",
      "3.609\n",
      "4.382\n",
      "4.301\n",
      "3.663\n",
      "3.754\n",
      "3.988\n",
      "3.674\n",
      "3.572\n",
      "5.009\n",
      "3.858\n",
      "3.406\n",
      "4.962\n",
      "4.548\n",
      "3.835\n",
      "4.005\n",
      "4.733\n",
      "3.474\n",
      "4.568\n",
      "3.506\n",
      "3.75\n",
      "3.747\n",
      "4.52\n",
      "2.82\n",
      "4.733\n",
      "4.174\n",
      "4.646\n",
      "3.434\n",
      "5.041\n",
      "4.648\n",
      "4.57\n",
      "3.922\n",
      "5.571\n",
      "3.844\n",
      "3.951\n",
      "4.003\n",
      "3.65\n",
      "3.437\n",
      "3.853\n",
      "3.486\n",
      "3.693\n",
      "4.385\n",
      "4.82\n",
      "3.611\n",
      "4.866\n",
      "3.164\n",
      "3.735\n",
      "3.811\n",
      "3.336\n",
      "4.546\n",
      "2.984\n",
      "3.573\n",
      "4.128\n",
      "4.237\n",
      "3.712\n",
      "3.404\n",
      "3.966\n",
      "3.893\n",
      "4.109\n",
      "3.813\n",
      "4.142\n",
      "3.959\n",
      "3.922\n",
      "3.527\n",
      "4.844\n",
      "2.9\n",
      "3.171\n",
      "3.818\n",
      "2.789\n",
      "3.881\n",
      "3.686\n",
      "3.597\n",
      "3.9\n",
      "4.391\n",
      "3.976\n",
      "3.518\n",
      "3.574\n",
      "3.965\n",
      "3.801\n",
      "4.693\n",
      "4.047\n",
      "3.463\n",
      "4.541\n",
      "3.839\n",
      "3.023\n",
      "3.826\n",
      "3.458\n",
      "4.45\n",
      "3.711\n",
      "4.785\n",
      "3.698\n",
      "3.987\n",
      "4.315\n",
      "3.859\n",
      "3.683\n",
      "2.863\n",
      "2.82\n",
      "3.227\n",
      "3.454\n",
      "2.749\n",
      "3.135\n",
      "3.517\n",
      "3.405\n",
      "2.799\n",
      "3.12\n",
      "4.3\n",
      "5.284\n",
      "4.091\n",
      "3.32\n",
      "3.969\n",
      "3.136\n",
      "4.651\n",
      "4.359\n",
      "4.218\n",
      "3.612\n",
      "3.881\n",
      "3.258\n",
      "3.436\n",
      "3.494\n",
      "4.097\n",
      "2.52\n",
      "3.13\n",
      "3.412\n",
      "3.576\n",
      "3.078\n",
      "3.675\n",
      "4.121\n",
      "3.641\n",
      "2.944\n",
      "3.752\n",
      "3.527\n",
      "4.456\n",
      "3.529\n",
      "3.657\n",
      "2.792\n",
      "3.897\n",
      "2.546\n",
      "4.003\n",
      "4.422\n",
      "4.414\n",
      "3.662\n",
      "3.164\n",
      "2.838\n",
      "2.852\n",
      "3.995\n",
      "4.045\n",
      "3.882\n",
      "3.268\n",
      "3.435\n",
      "3.823\n",
      "3.885\n",
      "3.676\n",
      "4.794\n",
      "3.849\n",
      "3.972\n",
      "3.921\n",
      "3.239\n",
      "3.428\n",
      "2.908\n",
      "4.062\n",
      "3.851\n",
      "3.097\n",
      "3.677\n",
      "3.411\n",
      "4.034\n",
      "4.046\n",
      "3.11\n",
      "3.761\n",
      "3.721\n",
      "2.855\n",
      "3.056\n",
      "4.052\n",
      "2.721\n",
      "3.384\n",
      "3.159\n",
      "3.205\n",
      "2.913\n",
      "3.093\n",
      "3.012\n",
      "3.773\n",
      "2.678\n",
      "3.503\n",
      "3.659\n",
      "3.574\n",
      "3.368\n",
      "2.089\n",
      "3.259\n",
      "4.135\n",
      "3.512\n",
      "4.24\n",
      "3.707\n",
      "4.7\n",
      "4.373\n",
      "3.186\n",
      "3.971\n",
      "2.939\n",
      "2.73\n",
      "3.653\n",
      "3.609\n",
      "3.836\n",
      "3.065\n",
      "3.202\n",
      "4.603\n",
      "3.209\n",
      "3.684\n",
      "4.051\n",
      "2.986\n",
      "2.962\n",
      "4.129\n",
      "2.529\n",
      "3.933\n",
      "3.262\n",
      "3.106\n",
      "3.533\n",
      "2.522\n",
      "3.098\n",
      "2.994\n",
      "3.578\n",
      "2.365\n",
      "2.952\n",
      "3.59\n",
      "3.073\n",
      "4.247\n",
      "4.129\n",
      "2.639\n",
      "3.065\n",
      "3.186\n",
      "3.49\n",
      "3.759\n",
      "3.391\n",
      "4.227\n",
      "2.373\n",
      "3.606\n",
      "3.398\n",
      "4.707\n",
      "3.526\n",
      "2.951\n",
      "3.163\n",
      "2.919\n",
      "3.563\n",
      "3.511\n",
      "4.253\n",
      "3.676\n",
      "3.509\n",
      "2.396\n",
      "3.735\n",
      "2.951\n",
      "3.453\n",
      "4.29\n",
      "3.814\n",
      "3.272\n",
      "3.126\n",
      "3.298\n",
      "4.097\n",
      "3.488\n",
      "3.589\n",
      "2.761\n",
      "3.845\n",
      "2.959\n",
      "3.923\n",
      "3.205\n",
      "3.634\n",
      "1.817\n",
      "3.326\n",
      "3.682\n",
      "2.961\n",
      "2.603\n",
      "2.837\n",
      "4.027\n",
      "2.732\n",
      "2.924\n",
      "3.223\n",
      "3.13\n",
      "3.388\n",
      "2.681\n",
      "3.208\n",
      "3.267\n",
      "3.458\n",
      "2.859\n",
      "3.311\n",
      "4.245\n",
      "2.437\n",
      "3.723\n",
      "4.2\n",
      "3.658\n",
      "3.184\n",
      "2.839\n",
      "3.947\n",
      "3.087\n",
      "2.891\n",
      "3.362\n",
      "3.022\n",
      "3.504\n",
      "2.828\n",
      "2.654\n",
      "2.642\n",
      "3.384\n",
      "3.552\n",
      "3.076\n",
      "3.335\n",
      "3.336\n",
      "2.722\n",
      "3.707\n",
      "3.403\n",
      "2.652\n",
      "3.098\n",
      "3.209\n",
      "3.406\n",
      "2.949\n",
      "3.82\n",
      "2.053\n",
      "2.521\n",
      "2.946\n",
      "3.895\n",
      "3.165\n",
      "3.146\n",
      "3.945\n",
      "3.376\n",
      "3.1\n",
      "4.03\n",
      "4.149\n",
      "2.913\n",
      "3.511\n",
      "2.752\n",
      "2.486\n",
      "3.334\n",
      "3.156\n",
      "2.783\n",
      "4.224\n",
      "3.333\n",
      "3.163\n",
      "3.594\n",
      "2.338\n",
      "3.68\n",
      "3.089\n",
      "3.144\n",
      "3.391\n",
      "2.389\n",
      "3.518\n",
      "3.013\n",
      "3.303\n",
      "2.54\n",
      "3.241\n",
      "2.809\n",
      "2.966\n",
      "3.642\n",
      "2.382\n",
      "3.354\n",
      "2.556\n",
      "2.357\n",
      "2.11\n",
      "3.348\n",
      "3.966\n",
      "2.437\n",
      "3.672\n",
      "2.975\n",
      "3.314\n",
      "4.028\n",
      "2.87\n",
      "2.307\n",
      "3.471\n",
      "2.596\n",
      "2.493\n",
      "3.277\n",
      "2.799\n",
      "3.413\n",
      "2.634\n",
      "2.543\n",
      "3.35\n",
      "3.677\n",
      "3.058\n",
      "3.713\n",
      "3.467\n",
      "3.341\n",
      "2.705\n",
      "3.689\n",
      "2.369\n",
      "4.238\n",
      "3.502\n",
      "2.238\n",
      "2.979\n",
      "3.635\n",
      "2.051\n",
      "3.458\n",
      "3.11\n",
      "3.372\n",
      "3.277\n",
      "4.589\n",
      "3.056\n",
      "2.915\n",
      "3.484\n",
      "3.817\n",
      "3.399\n",
      "2.402\n",
      "2.455\n",
      "2.716\n",
      "3.023\n",
      "2.888\n",
      "2.176\n",
      "2.91\n",
      "3.237\n",
      "4.354\n",
      "4.573\n",
      "2.709\n",
      "3.327\n",
      "3.13\n",
      "2.607\n",
      "2.811\n",
      "2.682\n",
      "2.236\n",
      "1.611\n",
      "2.004\n",
      "3.635\n",
      "2.8\n",
      "4.1\n",
      "3.64\n",
      "2.938\n",
      "2.947\n",
      "2.457\n",
      "2.597\n",
      "3.655\n",
      "2.556\n",
      "2.87\n",
      "2.481\n",
      "2.547\n",
      "2.869\n",
      "3.399\n",
      "2.972\n",
      "4.575\n",
      "2.919\n",
      "3.493\n",
      "2.71\n",
      "2.737\n",
      "3.376\n",
      "3.125\n",
      "3.617\n",
      "2.909\n",
      "2.084\n",
      "3.048\n",
      "2.934\n",
      "2.673\n",
      "3.47\n",
      "2.129\n",
      "2.844\n",
      "2.862\n",
      "3.278\n",
      "2.046\n",
      "2.953\n",
      "3.181\n",
      "3.037\n",
      "2.196\n",
      "2.995\n",
      "3.388\n",
      "1.929\n",
      "2.787\n",
      "2.697\n",
      "2.677\n",
      "3.24\n",
      "3.615\n",
      "2.898\n",
      "3.293\n",
      "3.127\n",
      "3.212\n",
      "3.548\n",
      "2.654\n",
      "2.254\n",
      "2.484\n",
      "3.357\n",
      "2.896\n",
      "3.455\n",
      "2.957\n",
      "4.585\n",
      "2.668\n",
      "3.636\n",
      "2.574\n",
      "2.718\n",
      "2.874\n",
      "2.814\n",
      "3.301\n",
      "3.074\n",
      "5.114\n",
      "2.416\n",
      "2.162\n",
      "2.999\n",
      "2.879\n",
      "3.762\n",
      "2.751\n",
      "2.61\n",
      "3.663\n",
      "2.723\n",
      "2.326\n",
      "2.827\n",
      "3.363\n",
      "3.705\n",
      "2.327\n",
      "3.07\n",
      "2.451\n",
      "2.824\n",
      "2.683\n",
      "2.961\n",
      "2.867\n",
      "2.643\n",
      "2.958\n",
      "3.07\n",
      "2.874\n",
      "3.107\n",
      "3.506\n",
      "2.91\n",
      "2.981\n",
      "2.517\n",
      "2.832\n",
      "2.551\n",
      "3.545\n",
      "2.832\n",
      "3.133\n",
      "3.747\n",
      "2.757\n",
      "3.537\n",
      "2.432\n",
      "3.49\n",
      "3.794\n",
      "2.97\n",
      "3.494\n",
      "2.864\n",
      "3.311\n",
      "2.917\n",
      "3.565\n",
      "3.91\n",
      "3.455\n",
      "3.056\n",
      "2.79\n",
      "3.137\n",
      "3.458\n",
      "2.115\n",
      "3.352\n",
      "2.85\n",
      "3.364\n",
      "2.81\n",
      "2.434\n",
      "3.175\n",
      "3.03\n",
      "3.984\n",
      "2.069\n",
      "2.84\n",
      "3.397\n",
      "3.207\n",
      "2.222\n",
      "2.526\n",
      "2.821\n",
      "2.506\n",
      "3.284\n",
      "3.086\n",
      "2.384\n",
      "2.261\n",
      "2.334\n",
      "2.424\n",
      "3.6\n",
      "3.201\n",
      "2.271\n",
      "2.559\n",
      "2.675\n",
      "2.484\n",
      "2.683\n",
      "2.652\n",
      "3.451\n",
      "2.856\n",
      "3.145\n",
      "2.999\n",
      "3.02\n",
      "2.45\n",
      "2.105\n",
      "2.178\n",
      "2.645\n",
      "2.832\n",
      "2.457\n",
      "2.39\n",
      "2.889\n",
      "4.243\n",
      "2.707\n",
      "3.481\n",
      "3.327\n",
      "2.201\n",
      "2.959\n",
      "4.237\n",
      "2.129\n",
      "2.441\n",
      "3.146\n",
      "1.828\n",
      "2.487\n",
      "3.257\n",
      "3.536\n",
      "3.174\n",
      "2.64\n",
      "2.425\n",
      "3.172\n",
      "2.738\n",
      "2.927\n",
      "2.798\n",
      "3.487\n",
      "3.06\n",
      "3.31\n",
      "3.296\n",
      "1.828\n",
      "2.544\n",
      "3.16\n",
      "2.803\n",
      "2.482\n",
      "2.542\n",
      "2.547\n",
      "3.551\n",
      "2.374\n",
      "3.338\n",
      "2.163\n",
      "2.346\n",
      "3.512\n",
      "2.998\n",
      "2.824\n",
      "2.56\n",
      "2.774\n",
      "2.462\n",
      "2.067\n",
      "3.273\n",
      "2.107\n",
      "3.427\n",
      "3.104\n",
      "2.715\n",
      "3.158\n",
      "2.46\n",
      "3.429\n",
      "3.421\n",
      "2.271\n",
      "2.063\n",
      "2.391\n",
      "4.818\n",
      "2.733\n",
      "2.957\n",
      "3.628\n",
      "3.343\n",
      "3.289\n",
      "3.289\n",
      "2.369\n",
      "2.548\n",
      "2.708\n",
      "2.734\n",
      "2.494\n",
      "2.529\n",
      "3.544\n",
      "2.029\n",
      "1.976\n",
      "2.721\n",
      "2.133\n",
      "2.186\n",
      "2.774\n",
      "2.569\n",
      "3.186\n",
      "2.308\n",
      "2.051\n",
      "3.02\n",
      "3.281\n",
      "3.187\n",
      "3.668\n",
      "2.628\n",
      "3.588\n",
      "2.783\n",
      "4.399\n",
      "3.034\n",
      "2.769\n",
      "3.534\n",
      "2.772\n",
      "2.457\n",
      "3.347\n",
      "3.142\n",
      "2.974\n",
      "2.684\n",
      "2.246\n",
      "2.429\n",
      "2.253\n",
      "2.635\n",
      "1.969\n",
      "2.283\n",
      "2.712\n",
      "3.028\n",
      "3.358\n",
      "2.914\n",
      "3.747\n",
      "2.861\n",
      "2.616\n",
      "2.235\n",
      "2.558\n",
      "3.287\n",
      "2.924\n",
      "3.091\n",
      "2.751\n",
      "3.732\n",
      "3.913\n",
      "2.79\n",
      "2.936\n",
      "3.693\n",
      "3.689\n",
      "3.414\n",
      "3.637\n",
      "3.653\n",
      "3.048\n",
      "3.126\n",
      "1.887\n",
      "2.598\n",
      "2.79\n",
      "2.573\n",
      "3.46\n",
      "2.46\n",
      "2.992\n",
      "2.513\n",
      "2.021\n",
      "2.922\n",
      "2.459\n",
      "3.059\n",
      "3.122\n",
      "2.147\n",
      "2.045\n",
      "2.575\n",
      "2.271\n",
      "3.034\n",
      "1.848\n",
      "2.541\n",
      "1.67\n",
      "2.483\n",
      "1.867\n",
      "2.184\n",
      "2.174\n",
      "2.937\n",
      "1.931\n",
      "2.439\n",
      "2.395\n",
      "2.83\n",
      "3.57\n",
      "2.461\n",
      "2.628\n",
      "3.122\n",
      "4.783\n",
      "2.823\n",
      "3.577\n",
      "2.579\n",
      "2.836\n",
      "2.65\n",
      "2.669\n",
      "3.138\n",
      "3.06\n",
      "2.205\n",
      "2.433\n",
      "2.68\n",
      "2.935\n",
      "2.932\n",
      "3.235\n",
      "2.539\n",
      "2.32\n",
      "2.352\n",
      "3.167\n",
      "2.89\n",
      "2.887\n",
      "3.777\n",
      "3.398\n",
      "2.391\n",
      "2.303\n",
      "2.303\n",
      "2.24\n",
      "3.397\n",
      "2.498\n",
      "2.935\n",
      "3.058\n",
      "3.213\n",
      "3.209\n",
      "2.741\n",
      "2.477\n",
      "2.008\n",
      "3.01\n",
      "3.057\n",
      "2.103\n",
      "2.485\n",
      "2.274\n",
      "2.912\n",
      "2.598\n",
      "1.697\n",
      "2.633\n",
      "1.895\n",
      "2.757\n",
      "3.117\n",
      "1.977\n",
      "3.07\n",
      "3.136\n",
      "3.113\n",
      "3.57\n",
      "3.099\n",
      "2.774\n",
      "2.74\n",
      "3.297\n",
      "2.893\n",
      "3.086\n",
      "3.062\n",
      "2.644\n",
      "2.36\n",
      "3.202\n",
      "2.588\n",
      "2.687\n",
      "3.284\n",
      "2.459\n",
      "2.76\n",
      "3.165\n",
      "2.858\n",
      "2.209\n",
      "2.306\n",
      "2.463\n",
      "3.077\n",
      "2.505\n",
      "2.56\n",
      "2.609\n",
      "2.39\n",
      "2.874\n",
      "2.389\n",
      "2.608\n",
      "3.103\n",
      "2.414\n",
      "3.593\n",
      "3.728\n",
      "2.879\n",
      "2.47\n",
      "2.834\n",
      "2.34\n",
      "2.359\n",
      "2.413\n",
      "1.939\n",
      "2.818\n",
      "3.142\n",
      "2.713\n",
      "2.329\n",
      "2.354\n",
      "2.746\n",
      "2.493\n",
      "3.028\n",
      "3.132\n",
      "3.306\n",
      "3.126\n",
      "2.284\n",
      "3.135\n",
      "3.049\n",
      "3.854\n",
      "2.26\n",
      "3.038\n",
      "2.35\n",
      "3.55\n",
      "2.693\n",
      "1.896\n",
      "2.476\n",
      "2.674\n",
      "2.462\n",
      "2.43\n",
      "2.15\n",
      "2.042\n",
      "2.648\n",
      "2.693\n",
      "2.396\n",
      "2.522\n",
      "3.146\n",
      "4.114\n",
      "2.497\n",
      "2.076\n",
      "2.21\n",
      "4.271\n",
      "2.575\n",
      "2.616\n",
      "2.14\n",
      "2.518\n",
      "2.977\n",
      "1.994\n",
      "2.079\n",
      "3.426\n",
      "2.262\n",
      "2.538\n",
      "2.76\n",
      "3.673\n",
      "3.224\n",
      "3.387\n",
      "2.906\n",
      "2.796\n",
      "4.54\n",
      "3.848\n",
      "3.042\n",
      "2.549\n",
      "2.475\n",
      "2.417\n",
      "2.744\n",
      "3.039\n",
      "2.637\n",
      "3.385\n",
      "2.983\n",
      "2.271\n",
      "2.647\n",
      "2.308\n",
      "2.592\n",
      "2.506\n",
      "2.529\n",
      "2.33\n",
      "2.107\n",
      "1.874\n",
      "3.176\n",
      "2.954\n",
      "2.628\n",
      "2.899\n",
      "3.259\n",
      "3.043\n",
      "1.719\n",
      "2.422\n",
      "2.779\n",
      "2.003\n",
      "2.488\n",
      "2.325\n",
      "2.353\n",
      "2.592\n",
      "3.058\n",
      "2.376\n",
      "2.494\n",
      "2.604\n",
      "2.753\n",
      "2.78\n",
      "3.226\n",
      "2.75\n",
      "3.369\n",
      "4.663\n",
      "2.724\n",
      "3.873\n",
      "2.738\n",
      "2.953\n",
      "2.782\n",
      "2.244\n",
      "2.907\n",
      "1.805\n",
      "2.425\n",
      "2.108\n",
      "2.962\n",
      "2.075\n",
      "3.376\n",
      "3.732\n",
      "2.439\n",
      "2.527\n",
      "3.416\n",
      "1.898\n",
      "3.408\n",
      "2.894\n",
      "3.232\n",
      "2.547\n",
      "3.12\n",
      "3.058\n",
      "4.162\n",
      "2.432\n",
      "3.597\n",
      "2.462\n",
      "2.394\n",
      "2.252\n",
      "3.167\n",
      "3.702\n",
      "3.125\n",
      "2.076\n",
      "2.119\n",
      "1.726\n",
      "2.682\n",
      "2.487\n",
      "3.055\n",
      "3.336\n",
      "3.011\n",
      "2.262\n",
      "2.74\n",
      "2.304\n",
      "2.487\n",
      "2.54\n",
      "2.796\n",
      "2.52\n",
      "3.054\n",
      "2.539\n",
      "2.841\n",
      "3.307\n",
      "2.701\n",
      "2.965\n",
      "3.467\n",
      "2.027\n",
      "2.752\n",
      "2.421\n",
      "3.527\n",
      "2.398\n",
      "1.933\n",
      "3.535\n",
      "1.86\n",
      "2.746\n",
      "2.423\n",
      "1.945\n",
      "2.302\n",
      "2.77\n",
      "3.188\n",
      "2.378\n",
      "2.763\n",
      "2.755\n",
      "2.553\n",
      "2.862\n",
      "2.248\n",
      "2.914\n",
      "2.984\n",
      "2.348\n",
      "2.969\n",
      "3.01\n",
      "2.913\n",
      "3.116\n",
      "2.271\n",
      "3.075\n",
      "2.957\n",
      "3.006\n",
      "2.351\n",
      "3.549\n",
      "2.566\n",
      "2.818\n",
      "2.632\n",
      "2.153\n",
      "2.227\n",
      "3.567\n",
      "2.594\n",
      "2.485\n",
      "2.645\n",
      "3.251\n",
      "2.773\n",
      "2.287\n",
      "2.153\n",
      "2.805\n",
      "2.725\n",
      "2.541\n",
      "2.344\n",
      "3.133\n",
      "2.727\n",
      "3.189\n",
      "2.783\n",
      "3.35\n",
      "3.572\n",
      "3.213\n",
      "2.964\n",
      "2.721\n",
      "2.301\n",
      "2.965\n",
      "2.671\n",
      "2.609\n",
      "2.089\n",
      "2.42\n",
      "3.328\n",
      "2.318\n",
      "2.151\n",
      "1.996\n",
      "2.922\n",
      "2.122\n",
      "3.321\n",
      "3.959\n",
      "2.17\n",
      "2.219\n",
      "2.901\n",
      "2.616\n",
      "2.481\n",
      "3.029\n",
      "2.137\n",
      "2.967\n",
      "2.872\n",
      "2.854\n",
      "3.02\n",
      "3.361\n",
      "2.438\n",
      "2.817\n",
      "2.894\n",
      "3.36\n",
      "3.573\n",
      "2.454\n",
      "3.047\n",
      "2.496\n",
      "2.988\n",
      "2.759\n",
      "2.719\n",
      "2.053\n",
      "2.956\n",
      "2.171\n",
      "2.575\n",
      "3.056\n",
      "3.735\n",
      "3.583\n",
      "1.78\n",
      "2.341\n",
      "2.498\n",
      "2.26\n",
      "2.807\n",
      "2.079\n",
      "3.283\n",
      "2.13\n",
      "2.993\n",
      "2.094\n",
      "3.223\n",
      "2.264\n",
      "3.105\n",
      "2.58\n",
      "2.02\n",
      "3.007\n",
      "2.561\n",
      "3.157\n",
      "3.172\n",
      "2.78\n",
      "2.767\n",
      "2.083\n",
      "1.902\n",
      "2.536\n",
      "2.987\n",
      "2.2\n",
      "2.304\n",
      "3.453\n",
      "2.648\n",
      "2.11\n",
      "2.78\n",
      "2.565\n",
      "2.463\n",
      "2.681\n",
      "2.913\n",
      "2.722\n",
      "2.706\n",
      "2.734\n",
      "1.862\n",
      "3.86\n",
      "2.785\n",
      "1.88\n",
      "3.42\n",
      "4.357\n",
      "2.529\n",
      "2.348\n",
      "3.077\n",
      "2.806\n",
      "3.228\n",
      "2.173\n",
      "2.134\n",
      "3.542\n",
      "3.869\n",
      "2.629\n",
      "2.324\n",
      "2.749\n",
      "3.952\n",
      "2.4\n",
      "2.258\n",
      "2.317\n",
      "2.429\n",
      "2.702\n",
      "3.34\n",
      "2.734\n",
      "2.726\n",
      "3.683\n",
      "3.179\n",
      "2.986\n",
      "2.759\n",
      "3.618\n",
      "3.397\n",
      "2.35\n",
      "3.236\n",
      "1.94\n",
      "2.483\n",
      "2.6\n",
      "2.762\n",
      "2.296\n",
      "2.512\n",
      "2.093\n",
      "2.215\n",
      "2.206\n",
      "2.795\n",
      "2.555\n",
      "2.916\n",
      "2.551\n",
      "2.667\n",
      "2.759\n",
      "2.885\n",
      "1.873\n",
      "2.472\n",
      "2.565\n",
      "2.504\n",
      "2.067\n",
      "2.424\n",
      "1.986\n",
      "2.354\n",
      "3.209\n",
      "2.435\n",
      "3.161\n",
      "2.536\n",
      "2.217\n",
      "2.939\n",
      "3.271\n",
      "3.032\n",
      "2.151\n",
      "2.361\n",
      "1.848\n",
      "2.847\n",
      "2.119\n",
      "3.635\n",
      "2.954\n",
      "1.869\n",
      "2.237\n",
      "2.624\n",
      "3.559\n",
      "3.033\n",
      "2.131\n",
      "3.71\n",
      "4.046\n",
      "2.455\n",
      "2.706\n",
      "2.042\n",
      "2.287\n",
      "2.207\n",
      "2.697\n",
      "2.856\n",
      "3.708\n",
      "2.393\n",
      "3.25\n",
      "3.199\n",
      "2.526\n",
      "2.681\n",
      "2.291\n",
      "3.44\n",
      "3.554\n",
      "3.646\n",
      "3.476\n",
      "2.601\n",
      "3.578\n",
      "2.257\n",
      "2.177\n",
      "2.32\n",
      "2.564\n",
      "1.989\n",
      "2.856\n",
      "3.942\n",
      "2.644\n",
      "2.868\n",
      "2.479\n",
      "1.821\n",
      "2.151\n",
      "2.002\n",
      "2.797\n",
      "2.036\n",
      "3.192\n",
      "2.365\n",
      "1.948\n",
      "2.891\n",
      "3.51\n",
      "2.43\n",
      "3.242\n",
      "3.098\n",
      "1.897\n",
      "2.416\n",
      "2.028\n",
      "2.489\n",
      "3.23\n",
      "3.41\n",
      "2.37\n",
      "3.954\n",
      "2.466\n",
      "2.098\n",
      "2.284\n",
      "1.759\n",
      "2.559\n",
      "2.977\n",
      "2.973\n",
      "2.77\n",
      "2.859\n",
      "2.403\n",
      "2.251\n",
      "3.251\n",
      "1.984\n",
      "3.194\n",
      "3.439\n",
      "3.09\n",
      "1.645\n",
      "2.904\n",
      "2.882\n",
      "2.139\n",
      "2.703\n",
      "1.574\n",
      "3.21\n",
      "2.536\n",
      "2.722\n",
      "3.304\n",
      "1.85\n",
      "2.857\n",
      "3.212\n",
      "3.852\n",
      "3.107\n",
      "1.813\n",
      "3.053\n",
      "3.14\n",
      "2.293\n",
      "2.573\n",
      "2.266\n",
      "2.569\n",
      "2.846\n",
      "3.946\n",
      "2.382\n",
      "2.284\n",
      "2.52\n",
      "2.713\n",
      "2.263\n",
      "3.912\n",
      "2.982\n",
      "3.471\n",
      "2.414\n",
      "3.252\n",
      "2.531\n",
      "2.41\n",
      "2.564\n",
      "2.619\n",
      "2.455\n",
      "2.748\n",
      "3.006\n",
      "2.814\n",
      "3.333\n",
      "2.873\n",
      "2.285\n",
      "2.564\n",
      "3.12\n",
      "2.867\n",
      "3.112\n",
      "3.082\n",
      "2.611\n",
      "2.454\n",
      "2.581\n",
      "2.256\n",
      "1.857\n",
      "2.147\n",
      "2.038\n",
      "3.013\n",
      "2.806\n",
      "3.783\n",
      "2.423\n",
      "2.355\n",
      "2.563\n",
      "2.721\n",
      "1.899\n",
      "2.901\n",
      "2.751\n",
      "2.261\n",
      "2.99\n",
      "1.535\n",
      "2.612\n",
      "3.919\n",
      "2.194\n",
      "2.635\n",
      "2.514\n",
      "2.418\n",
      "3.18\n",
      "2.609\n",
      "2.99\n",
      "4.033\n",
      "2.304\n",
      "2.546\n",
      "3.541\n",
      "3.775\n",
      "2.874\n",
      "2.904\n",
      "2.85\n",
      "1.854\n",
      "3.424\n",
      "3.663\n",
      "2.468\n",
      "2.413\n",
      "3.158\n",
      "2.374\n",
      "2.855\n",
      "1.961\n",
      "1.921\n",
      "2.953\n",
      "1.872\n",
      "1.964\n",
      "1.985\n",
      "2.73\n",
      "2.768\n",
      "2.057\n",
      "1.48\n",
      "3.483\n",
      "1.858\n",
      "2.168\n",
      "1.938\n",
      "3.589\n",
      "3.207\n",
      "3.003\n",
      "2.458\n",
      "2.429\n",
      "2.172\n",
      "2.76\n",
      "2.745\n",
      "2.53\n",
      "3.126\n",
      "2.497\n",
      "2.466\n",
      "2.218\n",
      "4.034\n",
      "2.751\n",
      "2.61\n",
      "3.058\n",
      "2.331\n",
      "3.106\n",
      "1.903\n",
      "3.168\n",
      "2.328\n",
      "2.2\n",
      "2.639\n",
      "2.588\n",
      "2.09\n",
      "3.497\n",
      "1.79\n",
      "1.989\n",
      "3.192\n",
      "2.535\n",
      "3.704\n",
      "2.637\n",
      "2.184\n",
      "3.019\n",
      "3.51\n",
      "2.261\n",
      "2.804\n",
      "3.015\n",
      "2.932\n",
      "3.084\n",
      "2.928\n",
      "1.765\n",
      "3.008\n",
      "2.189\n",
      "2.816\n",
      "2.581\n",
      "2.03\n",
      "2.68\n",
      "2.623\n",
      "3.639\n",
      "1.549\n",
      "1.895\n",
      "3.001\n",
      "3.181\n",
      "3.403\n",
      "3.086\n",
      "3.455\n",
      "2.724\n",
      "2.936\n",
      "4.024\n",
      "2.44\n",
      "2.255\n",
      "2.661\n",
      "2.666\n",
      "2.312\n",
      "2.225\n",
      "3.022\n",
      "1.982\n",
      "3.029\n",
      "3.969\n",
      "2.054\n",
      "2.823\n",
      "3.167\n",
      "3.115\n",
      "2.258\n",
      "2.135\n",
      "2.173\n",
      "2.44\n",
      "1.941\n",
      "2.567\n",
      "2.85\n",
      "2.372\n",
      "1.922\n",
      "2.469\n",
      "3.032\n",
      "2.288\n",
      "2.91\n",
      "2.947\n",
      "2.202\n",
      "3.841\n",
      "3.399\n",
      "2.781\n",
      "2.696\n",
      "1.684\n",
      "2.81\n",
      "2.965\n",
      "2.283\n",
      "2.107\n",
      "2.365\n",
      "2.466\n",
      "3.335\n",
      "3.552\n",
      "1.943\n",
      "2.438\n",
      "3.238\n",
      "2.906\n",
      "2.315\n",
      "2.946\n",
      "2.299\n",
      "2.225\n",
      "1.934\n",
      "2.523\n",
      "3.09\n",
      "2.545\n",
      "2.998\n",
      "2.694\n",
      "2.747\n",
      "1.689\n",
      "3.094\n",
      "2.851\n",
      "3.015\n",
      "2.852\n",
      "2.089\n",
      "3.447\n",
      "2.1\n",
      "2.478\n",
      "2.758\n",
      "3.028\n",
      "3.511\n",
      "2.165\n",
      "3.05\n",
      "2.944\n",
      "2.84\n",
      "2.186\n",
      "2.573\n",
      "2.736\n",
      "3.121\n",
      "2.534\n",
      "2.91\n",
      "2.379\n",
      "2.284\n",
      "3.243\n",
      "2.794\n",
      "2.11\n",
      "3.299\n",
      "2.886\n",
      "2.693\n",
      "2.345\n",
      "2.99\n",
      "2.459\n",
      "2.477\n",
      "2.382\n",
      "3.391\n",
      "2.36\n",
      "2.545\n",
      "3.155\n",
      "2.939\n",
      "2.885\n",
      "2.486\n",
      "1.855\n",
      "2.637\n",
      "2.737\n",
      "2.76\n",
      "2.437\n",
      "1.826\n",
      "2.452\n",
      "2.122\n",
      "2.133\n",
      "2.981\n",
      "2.684\n",
      "2.948\n",
      "2.81\n",
      "1.914\n",
      "4.081\n",
      "2.429\n",
      "3.574\n",
      "2.131\n",
      "3.014\n",
      "1.957\n",
      "2.59\n",
      "2.006\n",
      "2.727\n",
      "3.478\n",
      "1.99\n",
      "2.67\n",
      "3.132\n",
      "2.241\n",
      "2.03\n",
      "3.54\n",
      "2.476\n",
      "2.812\n",
      "2.353\n",
      "2.413\n",
      "2.256\n",
      "2.61\n",
      "2.979\n",
      "2.741\n",
      "3.124\n",
      "3.732\n",
      "3.239\n",
      "2.49\n",
      "2.671\n",
      "2.293\n",
      "3.058\n",
      "2.543\n",
      "2.591\n",
      "3.143\n",
      "2.012\n",
      "3.189\n",
      "2.584\n",
      "1.693\n",
      "2.764\n",
      "3.4\n",
      "2.738\n",
      "3.255\n",
      "2.939\n",
      "2.837\n",
      "2.031\n",
      "3.742\n",
      "3.134\n",
      "2.637\n",
      "2.763\n",
      "2.852\n",
      "2.5\n",
      "2.709\n",
      "2.441\n",
      "2.12\n",
      "3.42\n",
      "1.886\n",
      "2.734\n",
      "2.63\n",
      "1.642\n",
      "3.104\n",
      "1.951\n",
      "3.102\n",
      "2.718\n",
      "2.889\n",
      "3.631\n",
      "2.476\n",
      "2.546\n",
      "2.855\n",
      "2.888\n",
      "2.178\n",
      "2.508\n",
      "2.629\n",
      "1.197\n",
      "3.657\n",
      "2.739\n",
      "2.169\n",
      "2.296\n",
      "2.632\n",
      "3.128\n",
      "3.682\n",
      "2.406\n",
      "2.818\n",
      "2.392\n",
      "3.711\n",
      "3.508\n",
      "2.914\n",
      "2.601\n",
      "2.144\n",
      "2.669\n",
      "1.566\n",
      "2.312\n",
      "3.209\n",
      "2.624\n",
      "1.864\n",
      "1.997\n",
      "2.77\n",
      "3.164\n",
      "2.088\n",
      "3.796\n",
      "4.396\n",
      "3.33\n",
      "2.144\n",
      "2.202\n",
      "2.056\n",
      "2.532\n",
      "2.672\n",
      "2.0\n",
      "2.16\n",
      "2.339\n",
      "2.81\n",
      "2.634\n",
      "2.813\n",
      "3.021\n",
      "2.734\n",
      "2.376\n",
      "3.207\n",
      "2.225\n",
      "2.133\n",
      "2.517\n",
      "2.25\n",
      "2.677\n",
      "2.536\n",
      "3.255\n",
      "2.075\n",
      "2.539\n",
      "4.159\n",
      "3.088\n",
      "2.959\n",
      "2.249\n",
      "2.09\n",
      "2.997\n",
      "3.302\n",
      "1.574\n",
      "2.03\n",
      "3.014\n",
      "2.481\n",
      "2.991\n",
      "1.745\n",
      "2.888\n",
      "3.014\n",
      "3.03\n",
      "2.37\n",
      "2.581\n",
      "2.268\n",
      "4.045\n",
      "3.245\n",
      "2.02\n",
      "3.857\n",
      "3.205\n",
      "2.395\n",
      "2.517\n",
      "2.76\n",
      "2.263\n",
      "2.477\n",
      "2.344\n",
      "2.728\n",
      "3.422\n",
      "3.512\n",
      "2.605\n",
      "2.121\n",
      "2.57\n",
      "2.485\n",
      "2.33\n",
      "2.179\n",
      "2.587\n",
      "2.478\n",
      "2.386\n",
      "3.06\n",
      "4.14\n",
      "3.652\n",
      "2.466\n",
      "2.507\n",
      "2.469\n",
      "2.403\n",
      "2.23\n",
      "3.023\n",
      "2.998\n",
      "2.502\n",
      "2.045\n",
      "2.126\n",
      "2.635\n",
      "2.821\n",
      "2.61\n",
      "2.27\n",
      "2.201\n",
      "3.117\n",
      "2.555\n",
      "2.902\n",
      "3.055\n",
      "3.118\n",
      "2.063\n",
      "2.817\n",
      "1.98\n",
      "3.775\n",
      "2.882\n",
      "2.247\n",
      "2.073\n",
      "2.916\n",
      "2.401\n",
      "2.185\n",
      "2.984\n",
      "2.744\n",
      "2.748\n",
      "2.958\n",
      "2.754\n",
      "2.98\n",
      "2.736\n",
      "2.646\n",
      "2.655\n",
      "2.263\n",
      "3.509\n",
      "2.43\n",
      "2.04\n",
      "2.335\n",
      "2.637\n",
      "2.515\n",
      "2.601\n",
      "2.733\n",
      "3.326\n",
      "2.58\n",
      "2.206\n",
      "3.277\n",
      "3.054\n",
      "2.715\n",
      "2.877\n",
      "2.412\n",
      "2.636\n",
      "2.41\n",
      "2.279\n",
      "1.924\n",
      "3.119\n",
      "2.473\n",
      "3.071\n",
      "2.198\n",
      "3.005\n",
      "2.383\n",
      "2.365\n",
      "3.611\n",
      "3.445\n",
      "3.251\n",
      "3.04\n",
      "3.569\n",
      "1.388\n",
      "2.231\n",
      "2.832\n",
      "2.403\n",
      "2.997\n",
      "2.85\n",
      "2.037\n",
      "2.989\n",
      "3.386\n",
      "2.826\n",
      "2.5\n",
      "2.359\n",
      "2.675\n",
      "2.259\n",
      "2.392\n",
      "2.144\n",
      "3.136\n",
      "1.783\n",
      "3.189\n",
      "2.351\n",
      "2.324\n",
      "2.688\n",
      "2.066\n",
      "1.832\n",
      "2.154\n",
      "2.858\n",
      "2.82\n",
      "1.973\n",
      "2.803\n",
      "2.977\n",
      "2.325\n",
      "2.131\n",
      "4.118\n",
      "2.631\n",
      "2.33\n",
      "3.179\n",
      "3.699\n",
      "2.669\n",
      "2.234\n",
      "3.075\n",
      "2.344\n",
      "3.189\n",
      "1.845\n",
      "2.848\n",
      "2.275\n",
      "3.462\n",
      "2.325\n",
      "2.827\n",
      "3.016\n",
      "2.263\n",
      "2.528\n",
      "2.05\n",
      "2.709\n",
      "2.712\n",
      "2.488\n",
      "2.138\n",
      "2.737\n",
      "2.638\n",
      "3.246\n",
      "2.07\n",
      "2.477\n",
      "2.684\n",
      "2.227\n",
      "2.578\n",
      "3.438\n",
      "3.015\n",
      "2.235\n",
      "3.525\n",
      "3.935\n",
      "3.503\n",
      "2.106\n",
      "2.897\n",
      "2.888\n",
      "2.843\n",
      "2.826\n",
      "1.841\n",
      "2.359\n",
      "2.511\n",
      "2.021\n",
      "3.704\n",
      "2.374\n",
      "4.383\n",
      "2.837\n",
      "3.482\n",
      "2.323\n",
      "1.851\n",
      "2.187\n",
      "2.168\n",
      "2.417\n",
      "2.318\n",
      "3.684\n",
      "3.246\n",
      "2.91\n",
      "2.15\n",
      "2.074\n",
      "2.673\n",
      "2.485\n",
      "2.702\n",
      "3.473\n",
      "1.867\n",
      "2.621\n",
      "2.905\n",
      "2.474\n",
      "3.067\n",
      "4.054\n",
      "2.773\n",
      "2.829\n",
      "2.507\n",
      "2.578\n",
      "2.511\n",
      "2.586\n",
      "2.316\n",
      "3.368\n",
      "2.053\n",
      "2.432\n",
      "2.229\n",
      "1.903\n",
      "3.025\n",
      "1.802\n",
      "2.117\n",
      "4.237\n",
      "2.421\n",
      "2.335\n",
      "2.374\n",
      "3.194\n",
      "3.045\n",
      "2.071\n",
      "2.438\n",
      "2.485\n",
      "2.506\n",
      "2.308\n",
      "2.257\n",
      "3.257\n",
      "1.731\n",
      "2.023\n",
      "3.338\n",
      "2.536\n",
      "3.346\n",
      "3.423\n",
      "3.533\n",
      "2.789\n",
      "1.691\n",
      "3.36\n",
      "2.947\n",
      "2.233\n",
      "3.503\n",
      "2.266\n",
      "2.587\n",
      "2.464\n",
      "2.372\n",
      "2.192\n",
      "3.05\n",
      "1.981\n",
      "2.571\n",
      "1.93\n",
      "2.772\n",
      "2.064\n",
      "2.857\n",
      "3.378\n",
      "2.86\n",
      "3.276\n",
      "2.507\n",
      "2.649\n",
      "2.773\n",
      "2.85\n",
      "3.206\n",
      "2.609\n",
      "2.287\n",
      "2.023\n",
      "2.158\n",
      "1.989\n",
      "1.812\n",
      "3.574\n",
      "3.176\n",
      "2.727\n",
      "3.04\n",
      "3.089\n",
      "2.948\n",
      "2.534\n",
      "3.168\n",
      "3.954\n",
      "2.351\n",
      "2.749\n",
      "2.566\n",
      "2.473\n",
      "2.676\n",
      "2.158\n",
      "2.398\n",
      "3.369\n",
      "3.322\n",
      "1.736\n",
      "2.803\n",
      "2.951\n",
      "2.398\n",
      "1.985\n",
      "2.089\n",
      "2.386\n",
      "2.312\n",
      "2.969\n",
      "1.974\n",
      "2.671\n",
      "2.518\n",
      "2.248\n",
      "3.176\n",
      "2.554\n",
      "2.223\n",
      "2.375\n",
      "2.805\n",
      "2.518\n",
      "2.447\n",
      "2.957\n",
      "2.893\n",
      "3.219\n",
      "2.343\n",
      "2.717\n",
      "3.048\n",
      "3.061\n",
      "2.471\n",
      "3.015\n",
      "2.203\n",
      "2.412\n",
      "2.572\n",
      "3.666\n",
      "2.299\n",
      "3.12\n",
      "2.698\n",
      "2.09\n",
      "2.662\n",
      "3.154\n",
      "2.646\n",
      "2.018\n",
      "2.661\n",
      "2.221\n",
      "3.536\n",
      "3.236\n",
      "2.192\n",
      "2.912\n",
      "2.407\n",
      "1.898\n",
      "2.513\n",
      "2.572\n",
      "3.302\n",
      "2.633\n",
      "2.472\n",
      "2.299\n",
      "2.23\n",
      "3.477\n",
      "2.234\n",
      "2.756\n",
      "2.434\n",
      "2.432\n",
      "2.384\n",
      "1.914\n",
      "3.148\n",
      "2.627\n",
      "2.442\n",
      "2.402\n",
      "3.428\n",
      "2.757\n",
      "2.449\n",
      "2.325\n",
      "3.333\n",
      "3.167\n",
      "2.592\n",
      "3.185\n",
      "3.077\n",
      "2.515\n",
      "3.147\n",
      "2.724\n",
      "2.461\n",
      "2.911\n",
      "2.968\n",
      "2.924\n",
      "2.713\n",
      "2.878\n",
      "3.333\n",
      "2.183\n",
      "2.241\n",
      "1.732\n",
      "2.317\n",
      "2.841\n",
      "2.457\n",
      "2.853\n",
      "2.779\n",
      "2.88\n",
      "3.914\n",
      "2.4\n",
      "2.467\n",
      "1.67\n",
      "2.072\n",
      "2.464\n",
      "2.862\n",
      "3.149\n",
      "2.756\n",
      "2.637\n",
      "2.743\n",
      "2.788\n",
      "3.418\n",
      "2.706\n",
      "2.774\n",
      "2.307\n",
      "3.389\n",
      "2.14\n",
      "3.101\n",
      "2.933\n",
      "2.285\n",
      "2.087\n",
      "2.397\n",
      "2.702\n",
      "2.581\n",
      "3.082\n",
      "2.265\n",
      "2.38\n",
      "2.281\n",
      "2.421\n",
      "2.403\n",
      "2.822\n",
      "3.179\n",
      "2.892\n",
      "2.541\n",
      "2.993\n",
      "2.454\n",
      "2.43\n",
      "2.778\n",
      "2.09\n",
      "3.065\n",
      "2.824\n",
      "2.579\n",
      "2.903\n",
      "3.095\n",
      "4.247\n",
      "1.845\n",
      "2.679\n",
      "2.448\n",
      "1.674\n",
      "3.356\n",
      "2.974\n",
      "2.362\n",
      "2.671\n",
      "2.184\n",
      "2.591\n",
      "3.099\n",
      "2.415\n",
      "3.333\n",
      "2.001\n",
      "2.931\n",
      "3.108\n",
      "3.169\n",
      "2.616\n",
      "2.499\n",
      "2.286\n",
      "2.715\n",
      "2.261\n",
      "2.536\n",
      "2.77\n",
      "2.557\n",
      "3.288\n",
      "3.083\n",
      "2.049\n",
      "2.418\n",
      "3.099\n",
      "2.32\n",
      "2.497\n",
      "2.156\n",
      "2.839\n",
      "2.672\n",
      "2.843\n",
      "2.68\n",
      "2.031\n",
      "1.964\n",
      "2.923\n",
      "3.001\n",
      "3.434\n",
      "2.565\n",
      "2.692\n",
      "3.489\n",
      "2.832\n",
      "2.794\n",
      "2.932\n",
      "2.591\n",
      "2.192\n",
      "2.029\n",
      "2.908\n",
      "3.192\n",
      "2.938\n",
      "2.35\n",
      "2.852\n",
      "3.453\n",
      "3.031\n",
      "2.469\n",
      "2.307\n",
      "1.795\n",
      "2.681\n",
      "3.092\n",
      "1.498\n",
      "2.313\n",
      "3.476\n",
      "2.874\n",
      "3.201\n",
      "2.081\n",
      "1.834\n",
      "2.526\n",
      "2.397\n",
      "2.457\n",
      "2.834\n",
      "3.171\n",
      "2.9\n",
      "2.675\n",
      "2.468\n",
      "3.006\n",
      "3.334\n",
      "2.192\n",
      "2.6\n",
      "3.441\n",
      "2.848\n",
      "2.544\n",
      "2.069\n",
      "2.186\n",
      "2.54\n",
      "2.17\n",
      "1.953\n",
      "3.322\n",
      "2.647\n",
      "2.469\n",
      "2.585\n",
      "2.687\n",
      "3.489\n",
      "2.431\n",
      "2.771\n",
      "2.259\n",
      "2.057\n",
      "3.005\n",
      "1.968\n",
      "2.393\n",
      "2.797\n",
      "2.469\n",
      "3.907\n",
      "3.201\n",
      "2.306\n",
      "2.5\n",
      "2.848\n",
      "2.457\n",
      "3.018\n",
      "2.268\n",
      "2.673\n",
      "2.842\n",
      "2.38\n",
      "2.699\n",
      "2.707\n",
      "2.631\n",
      "2.399\n",
      "3.096\n",
      "3.014\n",
      "2.602\n",
      "2.604\n",
      "2.741\n",
      "2.326\n",
      "2.182\n",
      "2.629\n",
      "2.925\n",
      "2.279\n",
      "2.906\n",
      "2.64\n",
      "1.99\n",
      "2.705\n",
      "1.754\n",
      "2.576\n",
      "3.328\n",
      "2.95\n",
      "3.38\n",
      "3.256\n",
      "2.595\n",
      "2.872\n",
      "2.326\n",
      "3.18\n",
      "3.165\n",
      "1.766\n",
      "2.32\n",
      "3.53\n",
      "2.113\n",
      "2.368\n",
      "3.047\n",
      "2.771\n",
      "2.6\n",
      "3.101\n",
      "2.621\n",
      "2.614\n",
      "1.995\n",
      "2.112\n",
      "2.175\n",
      "2.347\n",
      "2.218\n",
      "2.931\n",
      "3.169\n",
      "3.049\n",
      "3.411\n",
      "2.297\n",
      "2.356\n",
      "3.071\n",
      "3.296\n",
      "2.613\n",
      "2.937\n",
      "2.672\n",
      "1.867\n",
      "3.497\n",
      "3.749\n",
      "2.543\n",
      "2.543\n",
      "2.784\n",
      "2.68\n",
      "3.022\n",
      "2.676\n",
      "3.023\n",
      "2.295\n",
      "2.762\n",
      "2.596\n",
      "2.628\n",
      "2.204\n",
      "2.122\n",
      "2.498\n",
      "2.289\n",
      "2.648\n",
      "1.757\n",
      "3.717\n",
      "2.573\n",
      "2.102\n",
      "2.343\n",
      "2.882\n",
      "2.643\n",
      "2.896\n",
      "2.603\n",
      "2.553\n",
      "1.673\n",
      "2.839\n",
      "2.486\n",
      "2.784\n",
      "2.728\n",
      "2.631\n",
      "1.888\n",
      "2.842\n",
      "2.489\n",
      "2.064\n",
      "4.715\n",
      "2.909\n",
      "2.691\n",
      "2.041\n",
      "2.659\n",
      "2.688\n",
      "2.343\n",
      "3.403\n",
      "2.298\n",
      "2.215\n",
      "2.275\n",
      "3.155\n",
      "2.744\n",
      "3.052\n",
      "2.86\n",
      "2.534\n",
      "2.392\n",
      "2.58\n",
      "2.933\n",
      "2.645\n",
      "2.348\n",
      "2.222\n",
      "2.86\n",
      "2.998\n",
      "2.62\n",
      "2.561\n",
      "3.224\n",
      "2.167\n",
      "2.131\n",
      "3.447\n",
      "2.728\n",
      "4.031\n",
      "1.828\n",
      "4.318\n",
      "2.076\n",
      "2.844\n",
      "2.544\n",
      "1.761\n",
      "3.576\n",
      "2.116\n",
      "2.981\n",
      "2.35\n",
      "2.131\n",
      "2.898\n",
      "2.894\n",
      "2.458\n",
      "2.481\n",
      "3.163\n",
      "2.658\n",
      "1.97\n",
      "2.211\n",
      "3.158\n",
      "2.662\n",
      "1.927\n",
      "2.385\n",
      "2.333\n",
      "2.427\n",
      "2.718\n",
      "2.835\n",
      "2.599\n",
      "3.247\n",
      "2.41\n",
      "2.961\n",
      "2.612\n",
      "3.561\n",
      "2.471\n",
      "1.993\n",
      "2.804\n",
      "1.887\n",
      "3.443\n",
      "3.301\n",
      "2.939\n",
      "2.461\n",
      "2.375\n",
      "2.249\n",
      "2.361\n",
      "2.65\n",
      "2.024\n",
      "2.677\n",
      "3.295\n",
      "3.18\n",
      "2.889\n",
      "3.198\n",
      "2.37\n",
      "2.729\n",
      "2.309\n",
      "3.308\n",
      "2.402\n",
      "2.129\n",
      "2.429\n",
      "3.249\n",
      "1.965\n",
      "3.426\n",
      "2.255\n",
      "2.71\n",
      "2.505\n",
      "3.252\n",
      "2.439\n",
      "2.699\n",
      "3.281\n",
      "1.963\n",
      "2.052\n",
      "2.556\n",
      "2.214\n",
      "2.55\n",
      "2.573\n",
      "2.384\n",
      "2.19\n",
      "3.449\n",
      "1.315\n",
      "2.571\n",
      "3.246\n",
      "1.637\n",
      "2.727\n",
      "3.195\n",
      "2.954\n",
      "2.712\n",
      "1.881\n",
      "2.14\n",
      "2.903\n",
      "2.652\n",
      "3.415\n",
      "2.41\n",
      "2.841\n",
      "2.422\n",
      "2.979\n",
      "2.711\n",
      "2.023\n",
      "3.243\n",
      "3.117\n",
      "2.176\n",
      "2.783\n",
      "2.523\n",
      "2.683\n",
      "2.4\n",
      "2.565\n",
      "2.042\n",
      "2.314\n",
      "2.372\n",
      "3.15\n",
      "2.534\n",
      "2.499\n",
      "3.433\n",
      "2.17\n",
      "2.244\n",
      "2.365\n",
      "2.732\n",
      "2.321\n",
      "4.17\n",
      "2.257\n",
      "4.084\n",
      "2.754\n",
      "2.921\n",
      "2.817\n",
      "2.373\n",
      "2.687\n",
      "2.064\n",
      "2.186\n",
      "1.966\n",
      "3.26\n",
      "2.13\n",
      "3.779\n",
      "2.257\n",
      "2.426\n",
      "2.32\n",
      "2.026\n",
      "2.255\n",
      "3.076\n",
      "2.568\n",
      "2.232\n",
      "2.184\n",
      "2.535\n",
      "2.796\n",
      "2.369\n",
      "3.064\n",
      "3.002\n",
      "3.124\n",
      "3.063\n",
      "1.911\n",
      "2.985\n",
      "2.426\n",
      "2.169\n",
      "3.603\n",
      "3.926\n",
      "3.474\n",
      "3.158\n",
      "2.724\n",
      "2.475\n",
      "2.479\n",
      "2.809\n",
      "2.341\n",
      "2.162\n",
      "2.405\n",
      "1.952\n",
      "2.558\n",
      "2.583\n",
      "2.988\n",
      "2.848\n",
      "3.275\n",
      "2.355\n",
      "2.73\n",
      "2.724\n",
      "2.82\n",
      "2.819\n",
      "2.067\n",
      "3.375\n",
      "2.59\n",
      "2.637\n",
      "2.911\n",
      "2.897\n",
      "1.911\n",
      "2.299\n",
      "3.408\n",
      "2.928\n",
      "3.639\n",
      "3.157\n",
      "2.75\n",
      "2.707\n",
      "3.731\n",
      "2.054\n",
      "2.326\n",
      "3.195\n",
      "2.636\n",
      "2.578\n",
      "2.364\n",
      "2.605\n",
      "1.676\n",
      "2.215\n",
      "3.15\n",
      "2.253\n",
      "2.263\n",
      "2.277\n",
      "1.967\n",
      "3.16\n",
      "4.167\n",
      "2.482\n",
      "2.547\n",
      "2.584\n",
      "2.974\n",
      "1.849\n",
      "1.998\n",
      "2.328\n",
      "2.879\n",
      "2.345\n",
      "2.796\n",
      "3.094\n",
      "2.346\n",
      "3.005\n",
      "2.502\n",
      "3.189\n",
      "2.387\n",
      "1.848\n",
      "3.232\n",
      "2.536\n",
      "2.414\n",
      "1.988\n",
      "1.844\n",
      "2.65\n",
      "2.372\n",
      "2.706\n",
      "2.556\n",
      "3.074\n",
      "2.162\n",
      "2.367\n",
      "2.731\n",
      "3.264\n",
      "2.61\n",
      "3.511\n",
      "3.833\n",
      "1.692\n",
      "2.879\n",
      "2.314\n",
      "3.281\n",
      "2.032\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    initera modell, loss_function, optimizer & dataloader\n",
    "\n",
    "\n",
    "model = neuron(input_size)           \n",
    "loss_function = torch.nn.L1Loss() \n",
    "optimizer = SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "train_dataloader = DataLoader(training_set,                 \n",
    "                              batch_size = batch_size,       \n",
    "                              shuffle=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#    träna\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "batch_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "    \n",
    "        y_true = batch[:,-1]\n",
    "        input_features = batch[:,:-1]\n",
    "\n",
    "        y_pred = model(input_features)\n",
    "        loss = loss_function(y_true, y_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "        batch_losses.append(batch_loss)\n",
    "        \n",
    "        print(np.round(batch_loss,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9d7a2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16143e21",
   "metadata": {},
   "source": [
    "Vi kan nu plotta loss-historiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "195de923",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_losses);\n",
    "plt.xlabel('batch');\n",
    "plt.ylabel('training loss (MAE)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657e46e",
   "metadata": {},
   "source": [
    "Losset som beräknades under den allra sista iteration av träning är"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c9fd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0322954654693604"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54178bf",
   "metadata": {},
   "source": [
    "Detta betyder att *medelfelet* av våra prediktions, på hela vårt träningssätt är det värdet du ser ovan! Men betygen för varje person är ju också satt mellan 0-20, så ett medelfel på värdet du ser ovan är inte helt katastrofalt dåligt.\n",
    "\n",
    "Det är ju dock ändå knappast optimalt - och anledningen är för att en Neuron är en ganska dålig modell :)\n",
    "\n",
    "Här ville vi ju dock bara lära oss grunderna i PyTorch. Vi kommer lära oss betydligt bättre kraftfullare modeller snart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221c4e6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b486c3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c44d2",
   "metadata": {},
   "source": [
    "## UPPGIFTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb36044",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17113e9",
   "metadata": {},
   "source": [
    "**0)**\n",
    "\n",
    "Kolla på plotten över lossen ovan. Hur tolkar du den? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e66a9",
   "metadata": {},
   "source": [
    "**1)** \n",
    "\n",
    "Låt oss direkt testa hur den tränade modellen presterar på vårt dataset. Välj själv en training sample, ange ett värde mellan 0-648.\n",
    "\n",
    "Kan du hitta några training samples som modellen predictar särskilt bra/dåligt på? Jämför felen du får i dina svar med medelfelet vi fick ovan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebd3fa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "005fd5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True grade       : 10.0\n",
      "Predicted grade  : 10.68544864654541\n"
     ]
    }
   ],
   "source": [
    "model.eval();                                        # sätt modellen i evaluerings/predicion läge\n",
    "\n",
    "training_sample = 40                                # TESTA OLIKA VÄRDEN PÅ DENNA\n",
    "\n",
    "y_true = training_set[training_sample, -1]           # extrahera sanna slutbetyget för givet training sample\n",
    "input_features = training_set[training_sample, :-1]  # extrahera alla input features för samma training sample\n",
    "\n",
    "y_prediction = model(input_features)                 # predicta slutbetyg, givet input features\n",
    "\n",
    "\n",
    "print('True grade       :', y_true.item())\n",
    "print('Predicted grade  :', y_prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0d259",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11104bb6",
   "metadata": {},
   "source": [
    "**2)**\n",
    "\n",
    "Åskådliggör modellens parametrar på nytt. \n",
    "\n",
    "Säkerställ att de har ändrats sedan vi initierade modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1d36b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9f3a4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd26a6",
   "metadata": {},
   "source": [
    "**3)**\n",
    "\n",
    "Gå nu tillbaks till träningsloopen och testa att köra igenom den för ett par olika värden på epochs, och plotta på nytt. \n",
    "\n",
    "Testa värden på epochs med början på 1 och sluta på 50. Exempelvis 1, 5, 10, 15, ..., 45, 50.\n",
    "\n",
    "Vad verkar hända?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee789c5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d098f6c",
   "metadata": {},
   "source": [
    "**4)**\n",
    "\n",
    "Återigen, gå tillbaks till träningsloopen. Sätt epochs = 100. Testa nu istället olika värden på learning rate\n",
    "\n",
    "Testa följande värden på learning rate, i tur ordning\n",
    "\n",
    "- 0.00001 \n",
    "- 0.01\n",
    "- 1\n",
    "\n",
    "och plotta på nytt vår loss. Vad verkar hända? \n",
    "\n",
    "*Hint: jämför lossen* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
